{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89fd8ff0-e8e6-4335-9224-a9f2b93a773b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T14:45:55.560201Z",
     "iopub.status.busy": "2024-05-31T14:45:55.560017Z",
     "iopub.status.idle": "2024-05-31T14:45:55.562112Z",
     "shell.execute_reply": "2024-05-31T14:45:55.561848Z",
     "shell.execute_reply.started": "2024-05-31T14:45:55.560188Z"
    }
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2dfe51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikhi\\Desktop\\ProjectX\\multitask_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\nikhi\\Desktop\\ProjectX\\multitask_env\\Lib\\site-packages\\timm\\models\\helpers.py:7: FutureWarning: Importing from timm.models.helpers is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "c:\\Users\\nikhi\\Desktop\\ProjectX\\multitask_env\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.multi import MultiTaskTrainer\n",
    "import datetime, os, glob\n",
    "\n",
    "model_name='mtyolov8l'\n",
    "# list_task = ['pose', 'segment', 'multitask']\n",
    "list_task = ['multitask']\n",
    "\n",
    "# list_model_type = ['', '_ECA']\n",
    "list_model_type = ['_ECA']\n",
    "# list_pretrained = ['', '_pretrained']\n",
    "list_pretrained = ['']\n",
    "# list_dataset = ['coco', 'cattleeyeview']\n",
    "list_dataset = ['coco']\n",
    "dir_mtYOLO_root = 'C:/Users/nikhi/Desktop/ProjectX'\n",
    "epochs = 1\n",
    "patience = 0\n",
    "device = [0]\n",
    "image_size = 640\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032cba4a-71af-478c-aedf-809e5d9c87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def time_now():\n",
    "    return str(datetime.datetime.now())\n",
    "    \n",
    "def yolo_train(task, \n",
    "         model_type, \n",
    "         dir_mtYOLO_root, \n",
    "         dataset,\n",
    "         pretrained='', \n",
    "         loss_type='', \n",
    "         device=[0],\n",
    "         epochs=1, \n",
    "         patience=0, \n",
    "         image_size=640,\n",
    "         batch_size=-1,\n",
    "         model_name='mtyolov8'\n",
    "         ):\n",
    "\n",
    "    ## Check if config files exist\n",
    "    dir_model = f\"{dir_mtYOLO_root}/config/model/{model_name}_{task}_{dataset}{model_type}.yaml\"\n",
    "    dir_data = f\"{dir_mtYOLO_root}/config/dataset/{dataset}_{task}.yaml\"\n",
    "    dir_log = f\"{os.path.dirname(dir_mtYOLO_root)}/logs\"\n",
    "    print(f\"{dir_model} exists: {os.path.exists(dir_model)}\")\n",
    "    print(f\"{dir_data} exists: {os.path.exists(dir_data)}\")\n",
    "\n",
    "    ## Naming configuration\n",
    "    model_name = dir_model.split('/')[-1].split('.')[0]\n",
    "    experiment_name = f'{time_now()[:13]}_{model_name}{pretrained}'\n",
    "    \n",
    "    args = dict(\n",
    "        model=dir_model, #Specifies the model file for training. Accepts a path to either a .pt pretrained model or a .yaml configuration file. Essential for defining the model structure or initializing weights.\n",
    "        data=dir_data, #Path to the dataset configuration file (e.g., coco128.yaml). This file contains dataset-specific parameters, including paths to training and validation data, class names, and number of classes.\n",
    "        project=f'{dir_log}', #None, #Name of the project directory where training outputs are saved. Allows for organized storage of different experiments.\n",
    "        name=f'{experiment_name}', #Name of the training run. Used for creating a subdirectory within the project folder, where training logs and outputs are stored.\n",
    "        exist_ok=True, #If True, allows overwriting of an existing project/name directory. Useful for iterative experimentation without needing to manually clear previous outputs.\n",
    "    \n",
    "        imgsz=image_size, #Target image size for training. All images are resized to this dimension before being fed into the model. Affects model accuracy and computational complexity.\n",
    "        batch=batch_size, #16, #Batch size for training, indicating how many images are processed before the model's internal parameters are updated. AutoBatch (batch=-1) dynamically adjusts the batch size based on GPU memory availability.\n",
    "        epochs=epochs, #Total number of training epochs. Each epoch represents a full pass over the entire dataset. Adjusting this value can affect training duration and model performance.\n",
    "        cache=True, #Enables caching of dataset images in memory (True/ram), on disk (disk), or disables it (False). Improves training speed by reducing disk I/O at the cost of increased memory usage.\n",
    "    #     fraction=1, #Specifies the fraction of the dataset to use for training. Allows for training on a subset of the full dataset, useful for experiments or when resources are limited.\n",
    "    #     seed=0, #Sets the random seed for training, ensuring reproducibility of results across runs with the same configurations.\n",
    "    #     deterministic=False, #Forces deterministic algorithm use, ensuring reproducibility but may affect performance and speed due to the restriction on non-deterministic algorithms.\n",
    "    #     pretrained=True, #Determines whether to start training from a pretrained model. Can be a boolean value or a string path to a specific model from which to load weights. Enhances training efficiency and model performance.\n",
    "    #     resume=False, #Resumes training from the last saved checkpoint. Automatically loads model weights, optimizer state, and epoch count, continuing training seamlessly.\n",
    "    #     freeze=None, #Freezes the first N layers of the model or specified layers by index, reducing the number of trainable parameters. Useful for fine-tuning or transfer learning.\n",
    "    #     time=None, #Maximum training time in hours. If set, this overrides the epochs argument, allowing training to automatically stop after the specified duration. Useful for time-constrained training scenarios.\n",
    "        patience=patience, #Number of epochs to wait without improvement in validation metrics before early stopping the training. Helps prevent overfitting by stopping training when performance plateaus.\n",
    "        verbose=False, #Enables verbose output during training, providing detailed logs and progress updates. Useful for debugging and closely monitoring the training process.\n",
    "    \n",
    "        device=device, #Specifies the computational device(s) for training: a single GPU (device=0), multiple GPUs (device=0,1), CPU (device=cpu), or MPS for Apple silicon (device=mps).\n",
    "        workers=32, #8, #Number of worker threads for data loading (per RANK if Multi-GPU training). Influences the speed of data preprocessing and feeding into the model, especially useful in multi-GPU setups.\n",
    "    \n",
    "        optimizer='auto', # 'AdamW' #Choice of optimizer for training. Options include SGD, Adam, AdamW, NAdam, RAdam, RMSProp etc., or auto for automatic selection based on model configuration. Affects convergence speed and stability.\n",
    "    #     lr0=0.01, #Initial learning rate (i.e. SGD=1E-2, Adam=1E-3) . Adjusting this value is crucial for the optimization process, influencing how rapidly model weights are updated.\n",
    "    #     warmup_epochs=3, #Number of epochs for learning rate warmup, gradually increasing the learning rate from a low value to the initial learning rate to stabilize training early on.\n",
    "    #     warmup_momentum=0.8, #Initial momentum for warmup phase, gradually adjusting to the set momentum over the warmup period.\n",
    "    #     warmup_bias_lr=0.1, #Learning rate for bias parameters during the warmup phase, helping stabilize model training in the initial epochs.\n",
    "    #     lrf=0.01, #Final learning rate as a fraction of the initial rate = (lr0 * lrf), used in conjunction with schedulers to adjust the learning rate over time.\n",
    "    #     cos_lr=False, #Utilizes a cosine learning rate scheduler, adjusting the learning rate following a cosine curve over epochs. Helps in managing learning rate for better convergence.\n",
    "    #     momentum=0.937, #Momentum factor for SGD or beta1 for Adam optimizers, influencing the incorporation of past gradients in the current update.\n",
    "    #     weight_decay=0.0005, #L2 regularization term, penalizing large weights to prevent overfitting.\n",
    "        \n",
    "        # mask_ratio=0, #4, #Downsample ratio for segmentation masks, affecting the resolution of masks used during training.\n",
    "        dropout=0, #Dropout rate for regularization in classification tasks, preventing overfitting by randomly omitting units during training.\n",
    "        \n",
    "    #     single_cls=False, #Treats all classes in multi-class datasets as a single class during training. Useful for binary classification tasks or when focusing on object presence rather than classification.\n",
    "        rect=False, #Enables rectangular training, optimizing batch composition for minimal padding. Can improve efficiency and speed but may affect model accuracy.\n",
    "        \n",
    "        close_mosaic=0, #10, #Disables mosaic data augmentation in the last N epochs to stabilize training before completion. Setting to 0 disables this feature.\n",
    "        # hsv_h=0.015, #0.0-1.0\tAdjusts the hue of the image by a fraction of the color wheel, introducing color variability. Helps the model generalize across different lighting conditions.\n",
    "        # hsv_s=0.7, #0.0-1.0\tAlters the saturation of the image by a fraction, affecting the intensity of colors. Useful for simulating different environmental conditions.\n",
    "        # hsv_v=0.4, #0.0-1.0\tModifies the value (brightness) of the image by a fraction, helping the model to perform well under various lighting conditions.\n",
    "        # degrees=0.0, #-180-+180\tRotates the image randomly within the specified degree range, improving the model's ability to recognize objects at various orientations.\n",
    "        # translate=0.0, #0.0-1.0\tTranslates the image horizontally and vertically by a fraction of the image size, aiding in learning to detect partially visible objects.\n",
    "        # scale=0.0, #>=0.0\tScales the image by a gain factor, simulating objects at different distances from the camera.\n",
    "        # shear=0.0, #-180-+180\tShears the image by a specified degree, mimicking the effect of objects being viewed from different angles.\n",
    "        # perspective=0.0, #0.0-0.001\tApplies a random perspective transformation to the image, enhancing the model's ability to understand objects in 3D space.\n",
    "        # flipud=0.0, #0.0-1.0\tFlips the image upside down with the specified probability, increasing the data variability without affecting the object's characteristics.\n",
    "        # fliplr=0.5, #0.0-1.0\tFlips the image left to right with the specified probability, useful for learning symmetrical objects and increasing dataset diversity.\n",
    "        mosaic=0.0, #0.0-1.0\tCombines four training images into one, simulating different scene compositions and object interactions. Highly effective for complex scene understanding.\n",
    "        # mixup=0.0, #0.0-1.0\tBlends two images and their labels, creating a composite image. Enhances the model's ability to generalize by introducing label noise and visual variability.\n",
    "        # copy_paste=0.0, #0.0-1.0\tCopies objects from one image and pastes them onto another, useful for increasing object instances and learning object occlusion.\n",
    "        # auto_augment='randaugment', # Automatically appliesa predefined augmentation policy (randaugment, autoaugment, augmix), optimizing for classification tasks by diversifying the visual features.\n",
    "        # erasing=0.4, #0.0-1.0\tRandomly erases a portion of the image during classification training, encouraging the model to focus on less obvious features for recognition.\n",
    "        \n",
    "        # box=5,#7.5, #Weight of the box loss component in the loss function, influencing how much emphasis is placed on accurately predicting bounding box coordinates.\n",
    "        # cls=5,#0.5, #Weight of the classification loss in the total loss function, affecting the importance of correct class prediction relative to other components.\n",
    "        # dfl=10,#1.5, #Weight of the distribution focal loss, used in certain YOLO versions for fine-grained classification.\n",
    "        # pose=20,#12, #Weight of the pose loss in models trained for pose estimation, influencing the emphasis on accurately predicting pose keypoints.\n",
    "        # kobj=10,#2, #Weight of the keypoint objectness loss in pose estimation models, balancing detection confidence with pose accuracy.\n",
    "        # nbs=64, #Nominal batch size for normalization of loss.\n",
    "        \n",
    "        # label_smoothing=0, #Applies label smoothing, softening hard labels to a mix of the target label and a uniform distribution over labels, can improve generalization.\n",
    "        overlap_mask=False, #True, #Determines whether segmentation masks should overlap during training, applicable in instance segmentation tasks.\n",
    "    \n",
    "        val=True, #Enables validation during training, allowing for periodic evaluation of model performance on a separate dataset.\n",
    "        plots=True, #Generates and saves plots of training and validation metrics, as well as prediction examples, providing visual insights into model performance and learning progression.\n",
    "        save=True, #Enables saving of training checkpoints and final model weights. Useful for resuming training or model deployment.\n",
    "        save_period=-1, #Frequency of saving model checkpoints, specified in epochs. A value of -1 disables this feature. Useful for saving interim models during long training sessions.\n",
    "    \n",
    "    #     profile=False, #Enables profiling of ONNX and TensorRT speeds during training, useful for optimizing model deployment.\n",
    "    #     amp=True, #Enables Automatic Mixed Precision (AMP) training, reducing memory usage and possibly speeding up training with minimal impact on accuracy.\n",
    "       \n",
    "    )\n",
    "\n",
    "    print(f'{model_name}{model_type}{pretrained} {task} training starts: {time_now()} ')\n",
    "\n",
    "    ## Start training multitask model\n",
    "    if task=='multitask':\n",
    "        trainer = MultiTaskTrainer(overrides=args)\n",
    "        print('done')\n",
    "        trainer.train()\n",
    "        \n",
    "    else:\n",
    "        ## Load pre-trained YOLO model\n",
    "        if pretrained!='':\n",
    "            ## Change name to load pre-trained YOLO model\n",
    "            if task=='segment':\n",
    "                task_type='seg'\n",
    "            else:\n",
    "                task_type=task\n",
    "            model = YOLO(dir_model).load(f'yolov8n-{task_type}.pt')\n",
    "        \n",
    "        else:\n",
    "            task_type=task\n",
    "            model = YOLO(dir_model)\n",
    "            \n",
    "        model.train(**args)\n",
    "\n",
    "    print(f'{model_name}{model_type}{pretrained} {task} training ends: {time_now()} \\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40b3b67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Visible Devices: 1\n",
      "Device 0: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "print(f\"CUDA Visible Devices: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f95891db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.207  Python-3.12.6 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=multi-task, mode=train, model=C:/Users/nikhi/Desktop/ProjectX/config/model/mtyolov8_multitask_coco_ECA.yaml, data=C:/Users/nikhi/Desktop/ProjectX/config/dataset/coco_multitask.yaml, epochs=1, patience=0, batch=2, imgsz=640, save=True, save_period=-1, cache=True, device=[0], workers=32, project=C:/Users/nikhi/Desktop/logs, name=2025-01-13 23_mtyolov8_multitask_coco_ECA, exist_ok=True, pretrained=True, optimizer=auto, verbose=False, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=False, mask_ratio=4, dropout=0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\n",
      "WARNING  no model scale passed. Assuming scale='n'.\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  1    115456  ultralytics.nn.modules.block.C2f             [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         3  ultralytics.nn.modules.conv.ECAAttention     [128]                         \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1         3  ultralytics.nn.modules.conv.ECAAttention     [64]                          \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 21                  -1  1         3  ultralytics.nn.modules.conv.ECAAttention     [128]                         \n",
      " 22                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 23             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 24                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 25                  -1  1         3  ultralytics.nn.modules.conv.ECAAttention     [256]                         \n",
      " 26        [17, 21, 25]  1   2846188  ultralytics.nn.modules.head.MultiTask        [1, [17, 3], 32, 64, [64, 128, 256]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: coco, Task: multitask, Model: _ECA\n",
      "C:/Users/nikhi/Desktop/ProjectX/config/model/mtyolov8_multitask_coco_ECA.yaml exists: True\n",
      "C:/Users/nikhi/Desktop/ProjectX/config/dataset/coco_multitask.yaml exists: True\n",
      "mtyolov8_multitask_coco_ECA_ECA multitask training starts: 2025-01-13 23:09:17.516005 \n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mtYOLOv8_multitask_coco_ECA summary: 462 layers, 5002952 parameters, 5002904 gradients, 12.7 GFLOPs\n",
      "\n",
      "Freezing layer 'model.26.dfl.conv.weight'\n",
      "Freezing layer 'model.26.pose_head.dfl.conv.weight'\n",
      "Freezing layer 'model.26.segment_head.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "c:\\Users\\nikhi\\Desktop\\ProjectX\\ultralytics\\ultralytics\\nn\\tasks.py:574: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(file, map_location='cpu'), file  # load\n",
      "c:\\Users\\nikhi\\Desktop\\ProjectX\\ultralytics\\ultralytics\\utils\\checks.py:583: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(True):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "c:\\Users\\nikhi\\Desktop\\ProjectX\\ultralytics\\ultralytics\\engine\\trainer.py:237: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\nikhi\\Desktop\\Mini-COCO\\labels\\train.cache... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the labels content :  [{'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\train\\\\000000000036.jpg', 'shape': (640, 481), 'cls': array([[          0]], dtype=float32), 'bboxes': array([[    0.67128,     0.61795,     0.64576,     0.72686]], dtype=float32), 'segments': [array([[    0.71784,     0.34481],\n",
      "       [    0.72385,     0.42156],\n",
      "       [    0.73888,     0.48025],\n",
      "       [    0.78393,     0.49831],\n",
      "       [    0.82297,     0.57958],\n",
      "       [    0.92509,     0.88431],\n",
      "       [    0.98516,     0.96331],\n",
      "       [    0.99416,     0.98137],\n",
      "       [    0.89805,     0.98137],\n",
      "       [    0.83499,     0.90914],\n",
      "       [    0.78393,     0.74661],\n",
      "       [    0.78092,     0.82788],\n",
      "       [    0.80495,     0.93848],\n",
      "       [    0.82597,     0.98137],\n",
      "       [     0.6758,     0.97461],\n",
      "       [    0.45052,     0.97234],\n",
      "       [    0.45052,     0.94752],\n",
      "       [    0.52262,     0.82788],\n",
      "       [    0.46555,     0.82788],\n",
      "       [    0.43551,     0.82563],\n",
      "       [     0.4205,      0.7895],\n",
      "       [    0.40247,     0.75791],\n",
      "       [     0.3484,     0.58634],\n",
      "       [    0.37243,     0.52314],\n",
      "       [    0.42349,     0.50734],\n",
      "       [    0.47757,     0.48928],\n",
      "       [    0.43551,     0.43511],\n",
      "       [    0.40247,      0.3877],\n",
      "       [    0.43252,     0.29514],\n",
      "       [    0.46555,     0.27483],\n",
      "       [    0.49258,     0.26355],\n",
      "       [    0.53763,     0.25452],\n",
      "       [    0.61272,     0.26355],\n",
      "       [    0.64576,     0.27258],\n",
      "       [    0.67879,     0.30869]], dtype=float32)], 'keypoints': array([[[    0.51975,     0.38125,           2],\n",
      "        [    0.55094,     0.34844,           2],\n",
      "        [    0.48856,     0.36719,           2],\n",
      "        [    0.64241,     0.35469,           2],\n",
      "        [    0.48856,     0.39531,           2],\n",
      "        [    0.73805,     0.52656,           2],\n",
      "        [    0.44699,     0.53438,           2],\n",
      "        [    0.84615,     0.77188,           2],\n",
      "        [    0.44283,      0.8125,           2],\n",
      "        [    0.92516,     0.96406,           2],\n",
      "        [    0.50728,     0.69844,           2],\n",
      "        [     0.7027,     0.94219,           2],\n",
      "        [    0.55509,        0.95,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\train\\\\000000000086.jpg', 'shape': (640, 512), 'cls': array([[          0]], dtype=float32), 'bboxes': array([[    0.42321,     0.57982,     0.25225,     0.58745]], dtype=float32), 'segments': [array([[    0.39518,     0.28609],\n",
      "       [    0.39518,     0.31973],\n",
      "       [    0.31391,     0.36681],\n",
      "       [    0.29709,     0.47892],\n",
      "       [    0.35315,      0.5148],\n",
      "       [    0.34754,     0.55964],\n",
      "       [    0.37557,     0.63362],\n",
      "       [    0.38957,      0.8018],\n",
      "       [     0.4092,     0.84439],\n",
      "       [    0.42602,     0.87355],\n",
      "       [    0.46805,     0.86458],\n",
      "       [    0.45684,     0.73902],\n",
      "       [    0.46525,     0.64933],\n",
      "       [    0.46525,     0.58206],\n",
      "       [    0.46805,     0.56189],\n",
      "       [    0.52131,     0.56638],\n",
      "       [     0.5101,     0.48789],\n",
      "       [    0.54934,     0.47669],\n",
      "       [     0.5157,     0.34216],\n",
      "       [    0.46525,     0.32197],\n",
      "       [    0.47365,     0.29283]], dtype=float32)], 'keypoints': array([[[    0.45508,     0.31094,           2],\n",
      "        [    0.46289,     0.29844,           2],\n",
      "        [    0.43555,     0.29844,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.40625,     0.29063,           2],\n",
      "        [    0.49805,     0.35156,           2],\n",
      "        [    0.36328,     0.35469,           2],\n",
      "        [    0.51562,     0.44063,           2],\n",
      "        [    0.31055,     0.45469,           2],\n",
      "        [    0.48438,     0.44688,           2],\n",
      "        [    0.38672,     0.44688,           2],\n",
      "        [    0.48242,      0.5375,           2],\n",
      "        [    0.41406,      0.5375,           2],\n",
      "        [    0.55664,     0.62656,           1],\n",
      "        [    0.42578,     0.62813,           2],\n",
      "        [    0.48242,     0.75781,           1],\n",
      "        [    0.39844,     0.79531,           2]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\train\\\\000000000113.jpg', 'shape': (640, 416), 'cls': array([[          0],\n",
      "       [          0],\n",
      "       [          0]], dtype=float32), 'bboxes': array([[    0.19274,     0.40462,     0.36466,     0.71106],\n",
      "       [    0.91032,     0.41346,     0.17935,     0.51289],\n",
      "       [    0.59118,     0.37191,     0.47019,      0.6045]], dtype=float32), 'segments': [array([[     0.2049,    0.067156],\n",
      "       [    0.18406,     0.10102],\n",
      "       [    0.17363,     0.10778],\n",
      "       [    0.17363,     0.12811],\n",
      "       [    0.17711,     0.15745],\n",
      "       [    0.18752,     0.18453],\n",
      "       [   0.038197,     0.23872],\n",
      "       [   0.010409,     0.38319],\n",
      "       [   0.017356,     0.44639],\n",
      "       [   0.097236,     0.54572],\n",
      "       [    0.07988,     0.76016],\n",
      "       [    0.10418,     0.75112],\n",
      "       [   0.097236,     0.72405],\n",
      "       [    0.10418,     0.71502],\n",
      "       [    0.22226,     0.70598],\n",
      "       [     0.2188,     0.65406],\n",
      "       [     0.2188,     0.65406],\n",
      "       [    0.20836,     0.64503],\n",
      "       [    0.36118,     0.63148],\n",
      "       [    0.35769,     0.48928],\n",
      "       [    0.36812,      0.4193],\n",
      "       [    0.37507,     0.31998],\n",
      "       [     0.3438,     0.22066],\n",
      "       [    0.32298,     0.20937],\n",
      "       [    0.33339,     0.18228],\n",
      "       [    0.33339,     0.13036],\n",
      "       [    0.31255,    0.085219],\n",
      "       [    0.27435,    0.058125],\n",
      "       [    0.25699,    0.049094],\n",
      "       [    0.22575,    0.051359],\n",
      "       [    0.18752,    0.060391],\n",
      "       [    0.18752,    0.069406]], dtype=float32), array([[    0.94519,     0.18769],\n",
      "       [    0.96608,     0.17814],\n",
      "       [    0.97613,     0.17311],\n",
      "       [    0.98774,     0.16658],\n",
      "       [    0.99625,     0.15953],\n",
      "       [    0.99935,     0.15702],\n",
      "       [          1,     0.34508],\n",
      "       [          1,     0.35664],\n",
      "       [          1,      0.4557],\n",
      "       [          1,     0.55627],\n",
      "       [          1,     0.58342],\n",
      "       [    0.98774,     0.59548],\n",
      "       [    0.98928,     0.65331],\n",
      "       [     0.9862,     0.66991],\n",
      "       [    0.82065,     0.62314],\n",
      "       [    0.83226,     0.56984],\n",
      "       [    0.84077,     0.54872],\n",
      "       [    0.85469,     0.48839],\n",
      "       [    0.85699,     0.47128],\n",
      "       [    0.84154,     0.44363],\n",
      "       [    0.83998,     0.38833],\n",
      "       [    0.84618,     0.36167],\n",
      "       [    0.85699,     0.35564],\n",
      "       [    0.86243,     0.35313],\n",
      "       [    0.85312,     0.35061],\n",
      "       [     0.8655,     0.30536],\n",
      "       [    0.87945,     0.28122],\n",
      "       [    0.88716,     0.27267],\n",
      "       [    0.88716,     0.26061],\n",
      "       [    0.88716,     0.24552],\n",
      "       [    0.89801,     0.22591],\n",
      "       [    0.90882,     0.20781],\n",
      "       [    0.92353,     0.19675]], dtype=float32), array([[    0.37339,      0.6337],\n",
      "       [    0.35608,     0.51461],\n",
      "       [    0.38029,     0.29662],\n",
      "       [    0.51858,     0.24944],\n",
      "       [    0.50476,     0.22922],\n",
      "       [    0.47709,     0.20673],\n",
      "       [    0.47019,     0.18652],\n",
      "       [    0.46327,      0.1618],\n",
      "       [    0.46673,     0.13933],\n",
      "       [    0.49091,    0.098875],\n",
      "       [    0.51858,    0.074156],\n",
      "       [    0.57736,    0.069656],\n",
      "       [    0.62921,    0.085391],\n",
      "       [     0.6707,     0.10786],\n",
      "       [    0.71911,     0.14831],\n",
      "       [    0.65688,     0.21123],\n",
      "       [    0.63267,      0.2337],\n",
      "       [    0.72601,     0.25394],\n",
      "       [    0.74676,     0.27866],\n",
      "       [    0.77789,     0.33708],\n",
      "       [    0.82627,     0.44045],\n",
      "       [    0.82281,     0.46067],\n",
      "       [    0.78132,     0.45842],\n",
      "       [    0.72601,     0.57078],\n",
      "       [    0.75714,     0.62697],\n",
      "       [    0.74329,     0.64944],\n",
      "       [     0.6707,     0.67416],\n",
      "       [    0.64995,     0.66742]], dtype=float32)], 'keypoints': array([[[    0.27644,     0.17188,           2],\n",
      "        [    0.30529,     0.15156,           2],\n",
      "        [    0.24279,     0.15469,           2],\n",
      "        [          0,           0,           0],\n",
      "        [     0.1851,        0.15,           2],\n",
      "        [    0.32212,      0.2375,           2],\n",
      "        [    0.11298,     0.25469,           2],\n",
      "        [    0.44231,     0.40312,           1],\n",
      "        [   0.045673,     0.40625,           2],\n",
      "        [    0.56971,     0.45469,           1],\n",
      "        [    0.11539,     0.55313,           2],\n",
      "        [    0.32933,     0.51094,           2],\n",
      "        [    0.17788,     0.52969,           2],\n",
      "        [    0.30048,     0.71406,           1],\n",
      "        [    0.15625,     0.72969,           1],\n",
      "        [    0.33413,     0.89531,           1],\n",
      "        [    0.15144,     0.91094,           1]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [    0.95913,     0.20312,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.98077,     0.32969,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [    0.92308,     0.36719,           2],\n",
      "        [    0.98077,     0.55469,           2],\n",
      "        [    0.89904,     0.56719,           2],\n",
      "        [    0.95433,     0.69844,           1],\n",
      "        [    0.83654,         0.7,           1]],\n",
      "\n",
      "       [[    0.56731,     0.19844,           2],\n",
      "        [    0.59856,     0.17812,           2],\n",
      "        [    0.53606,     0.17969,           2],\n",
      "        [    0.62981,     0.18594,           2],\n",
      "        [    0.49519,     0.19219,           2],\n",
      "        [    0.70433,     0.30312,           2],\n",
      "        [     0.4375,     0.30625,           2],\n",
      "        [    0.73558,     0.44375,           2],\n",
      "        [    0.42788,     0.45625,           2],\n",
      "        [    0.68029,     0.56094,           2],\n",
      "        [    0.54567,     0.50625,           2],\n",
      "        [    0.66587,     0.58281,           2],\n",
      "        [    0.45433,      0.5875,           2],\n",
      "        [    0.63221,     0.81094,           1],\n",
      "        [    0.48798,     0.81406,           1],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\train\\\\000000000136.jpg', 'shape': (374, 500), 'cls': array([[          0],\n",
      "       [          0]], dtype=float32), 'bboxes': array([[    0.05522,     0.65123,     0.10708,     0.68904],\n",
      "       [    0.06892,     0.58202,     0.13784,     0.83596]], dtype=float32), 'segments': [array([[    0.00836,     0.30671],\n",
      "       [    0.04184,     0.32684],\n",
      "       [    0.05856,     0.33577],\n",
      "       [     0.0686,     0.34473],\n",
      "       [      0.082,      0.3604],\n",
      "       [    0.09036,     0.40289],\n",
      "       [    0.08366,     0.43869],\n",
      "       [    0.08366,     0.46554],\n",
      "       [    0.08702,     0.47674],\n",
      "       [      0.082,     0.49463],\n",
      "       [     0.0686,     0.51923],\n",
      "       [    0.05856,     0.53936],\n",
      "       [     0.0502,      0.5662],\n",
      "       [     0.0435,     0.58634],\n",
      "       [    0.04184,     0.62885],\n",
      "       [    0.04016,     0.66687],\n",
      "       [    0.07196,     0.75636],\n",
      "       [    0.10208,     0.80783],\n",
      "       [    0.10876,     0.85481],\n",
      "       [     0.0937,     0.87941],\n",
      "       [    0.09036,     0.89283],\n",
      "       [    0.09204,     0.91968],\n",
      "       [    0.09204,     0.96441],\n",
      "       [    0.09204,     0.98679],\n",
      "       [    0.08366,     0.99575],\n",
      "       [    0.00168,      0.9935],\n",
      "       [    0.01004,     0.31342]], dtype=float32), array([[    0.08404,     0.36628],\n",
      "       [    0.06052,     0.33484],\n",
      "       [     0.0437,     0.32134],\n",
      "       [          0,     0.30786],\n",
      "       [          0,     0.18428],\n",
      "       [    0.03026,     0.16628],\n",
      "       [    0.06556,     0.16404],\n",
      "       [    0.10254,     0.18877],\n",
      "       [    0.10926,     0.22471],\n",
      "       [    0.11598,     0.25842],\n",
      "       [    0.12438,     0.26741],\n",
      "       [    0.11766,     0.29663],\n",
      "       [    0.10926,     0.29663],\n",
      "       [    0.09918,     0.35505],\n",
      "       [    0.09414,     0.36628],\n",
      "       [    0.08404,     0.36628],\n",
      "       [    0.08068,     0.48989],\n",
      "       [    0.05884,     0.53709],\n",
      "       [    0.04874,      0.5573],\n",
      "       [    0.02858,     0.63821],\n",
      "       [     0.0353,     0.69663],\n",
      "       [    0.05378,     0.73035],\n",
      "       [    0.09582,     0.78877],\n",
      "       [    0.11262,     0.82471],\n",
      "       [    0.08908,     0.89214],\n",
      "       [    0.08908,     0.91685],\n",
      "       [    0.08908,           1],\n",
      "       [    0.13784,           1],\n",
      "       [    0.13112,     0.95955],\n",
      "       [    0.12102,     0.92358],\n",
      "       [    0.12774,     0.89438],\n",
      "       [    0.13616,      0.7146],\n",
      "       [    0.12774,     0.64944],\n",
      "       [    0.09918,     0.54158],\n",
      "       [    0.08068,     0.48989]], dtype=float32)], 'keypoints': array([[[      0.076,     0.48396,           2],\n",
      "        [          0,           0,           0],\n",
      "        [      0.074,     0.44385,           2],\n",
      "        [          0,           0,           0],\n",
      "        [       0.02,     0.45722,           2],\n",
      "        [          0,           0,           0],\n",
      "        [      0.008,     0.65775,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [      0.104,      0.2754,           2],\n",
      "        [          0,           0,           0],\n",
      "        [      0.088,     0.27273,           2],\n",
      "        [          0,           0,           0],\n",
      "        [      0.044,     0.47059,           1],\n",
      "        [          0,           0,           0],\n",
      "        [      0.028,     0.70856,           1],\n",
      "        [          0,           0,           0],\n",
      "        [      0.086,     0.90909,           1],\n",
      "        [          0,           0,           0],\n",
      "        [      0.064,     0.90909,           1],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\train\\\\000000000151.jpg', 'shape': (640, 480), 'cls': array([[          0]], dtype=float32), 'bboxes': array([[    0.93727,     0.13773,    0.063667,     0.08325]], dtype=float32), 'segments': [array([[    0.91663,     0.16903],\n",
      "       [    0.91146,     0.16128],\n",
      "       [    0.91231,     0.15483],\n",
      "       [     0.9106,     0.14838],\n",
      "       [    0.90544,     0.14192],\n",
      "       [    0.90544,     0.13547],\n",
      "       [    0.90544,     0.13095],\n",
      "       [    0.90717,      0.1245],\n",
      "       [    0.90887,     0.12386],\n",
      "       [    0.90629,     0.11869],\n",
      "       [    0.90975,     0.11095],\n",
      "       [    0.92523,      0.1045],\n",
      "       [    0.93125,     0.10063],\n",
      "       [    0.93813,    0.099969],\n",
      "       [    0.94329,    0.099328],\n",
      "       [     0.9519,    0.096109],\n",
      "       [    0.95533,     0.09675],\n",
      "       [    0.96137,     0.09675],\n",
      "       [    0.96481,     0.09675],\n",
      "       [     0.9674,     0.09675],\n",
      "       [     0.9691,    0.097391],\n",
      "       [    0.95363,     0.17483],\n",
      "       [    0.94846,      0.1787],\n",
      "       [    0.93642,     0.17936],\n",
      "       [    0.93125,     0.17936],\n",
      "       [      0.939,     0.17483],\n",
      "       [    0.93813,     0.16709],\n",
      "       [    0.93125,     0.16322],\n",
      "       [    0.92437,     0.16322],\n",
      "       [    0.92179,     0.16452],\n",
      "       [    0.91748,     0.16773]], dtype=float32)], 'keypoints': array([[[    0.92708,     0.15781,           2],\n",
      "        [       0.95,      0.1375,           2],\n",
      "        [    0.91458,     0.14687,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB True): 100%|██████████| 5/5 [00:00<00:00, 714.39it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\nikhi\\Desktop\\Mini-COCO\\labels\\val.cache... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the labels content :  [{'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\val\\\\000000000165.jpg', 'shape': (536, 640), 'cls': array([[          0],\n",
      "       [          0]], dtype=float32), 'bboxes': array([[    0.68784,     0.60088,      0.5987,     0.79825],\n",
      "       [    0.28606,     0.51573,     0.55331,     0.94157]], dtype=float32), 'segments': [array([[    0.42047,     0.63968],\n",
      "       [    0.39191,     0.63696],\n",
      "       [    0.38848,     0.64106],\n",
      "       [    0.39991,     0.66151],\n",
      "       [    0.40677,     0.67242],\n",
      "       [    0.41591,     0.67925],\n",
      "       [    0.41705,     0.69017],\n",
      "       [    0.42961,     0.70108],\n",
      "       [    0.45019,     0.70381],\n",
      "       [    0.46847,     0.72019],\n",
      "       [    0.51759,     0.73791],\n",
      "       [    0.59186,     0.75429],\n",
      "       [    0.66727,     0.72974],\n",
      "       [    0.69927,     0.70927],\n",
      "       [    0.70497,     0.72563],\n",
      "       [    0.70155,     0.77612],\n",
      "       [    0.70497,     0.84297],\n",
      "       [    0.71183,     0.87299],\n",
      "       [    0.69813,     0.95211],\n",
      "       [    0.69813,     0.99849],\n",
      "       [    0.98719,           1],\n",
      "       [    0.97919,     0.91118],\n",
      "       [    0.98377,     0.90162],\n",
      "       [    0.96091,     0.79931],\n",
      "       [    0.94491,     0.77065],\n",
      "       [    0.95291,     0.74883],\n",
      "       [    0.96662,     0.64787],\n",
      "       [    0.97919,     0.59877],\n",
      "       [    0.98033,     0.56739],\n",
      "       [    0.97577,     0.50054],\n",
      "       [    0.95063,     0.43914],\n",
      "       [     0.8992,     0.39685],\n",
      "       [    0.85352,     0.39004],\n",
      "       [    0.84552,     0.37366],\n",
      "       [     0.8318,     0.38185],\n",
      "       [    0.82609,     0.37366],\n",
      "       [     0.8398,     0.35047],\n",
      "       [    0.86722,     0.34774],\n",
      "       [     0.8695,     0.32728],\n",
      "       [    0.86494,     0.30953],\n",
      "       [     0.8558,     0.27134],\n",
      "       [    0.84438,     0.23313],\n",
      "       [    0.81352,     0.20586],\n",
      "       [    0.78495,     0.20175],\n",
      "       [    0.74267,     0.21541],\n",
      "       [    0.71641,      0.2386],\n",
      "       [    0.69697,     0.27543],\n",
      "       [    0.69127,       0.315],\n",
      "       [    0.69012,     0.32319],\n",
      "       [    0.69469,      0.3341],\n",
      "       [    0.69355,      0.3573],\n",
      "       [    0.69697,     0.36821],\n",
      "       [    0.69127,     0.37776],\n",
      "       [    0.70041,     0.38868],\n",
      "       [    0.71525,      0.3914],\n",
      "       [    0.71755,      0.4105],\n",
      "       [    0.71983,     0.42414],\n",
      "       [    0.72897,     0.43914],\n",
      "       [    0.74953,      0.4405],\n",
      "       [    0.71869,     0.47188],\n",
      "       [    0.69697,     0.50054],\n",
      "       [    0.67984,     0.52509],\n",
      "       [    0.66384,     0.54147],\n",
      "       [    0.61928,     0.49918],\n",
      "       [    0.59642,     0.48008],\n",
      "       [    0.57358,     0.47052],\n",
      "       [    0.51645,     0.48144],\n",
      "       [    0.51302,     0.48552],\n",
      "       [    0.52102,     0.49371],\n",
      "       [    0.54502,     0.49507],\n",
      "       [    0.52673,     0.50463],\n",
      "       [    0.50731,     0.53056],\n",
      "       [    0.51873,     0.53465],\n",
      "       [    0.53702,     0.53328],\n",
      "       [    0.54387,     0.54828],\n",
      "       [     0.5553,      0.5592],\n",
      "       [    0.55758,     0.56466],\n",
      "       [    0.59986,     0.55784],\n",
      "       [    0.59414,     0.57147],\n",
      "       [    0.62728,     0.60013],\n",
      "       [    0.61586,     0.61923],\n",
      "       [    0.59642,      0.6356],\n",
      "       [    0.58158,     0.64379],\n",
      "       [    0.55872,     0.63832],\n",
      "       [     0.5393,     0.65742],\n",
      "       [    0.52788,     0.66015],\n",
      "       [    0.51073,     0.66015],\n",
      "       [    0.48559,     0.64924],\n",
      "       [    0.46275,     0.65198],\n",
      "       [    0.45019,     0.62877],\n",
      "       [    0.42161,     0.60285],\n",
      "       [    0.41247,     0.59877],\n",
      "       [    0.41247,     0.60558],\n",
      "       [    0.42619,     0.63287],\n",
      "       [    0.42847,     0.63832],\n",
      "       [    0.42161,     0.64106]], dtype=float32), array([[   0.052703,     0.98651],\n",
      "       [   0.080922,     0.75056],\n",
      "       [      0.032,     0.73034],\n",
      "       [  0.0094062,     0.69213],\n",
      "       [   0.045172,     0.34832],\n",
      "       [     0.1562,     0.29662],\n",
      "       [    0.19197,     0.27416],\n",
      "       [    0.19573,     0.24494],\n",
      "       [    0.17503,     0.18651],\n",
      "       [     0.1882,     0.15955],\n",
      "       [    0.20514,    0.076399],\n",
      "       [    0.23902,    0.044944],\n",
      "       [    0.30866,    0.069664],\n",
      "       [      0.335,     0.13259],\n",
      "       [      0.335,     0.18427],\n",
      "       [    0.30677,     0.26293],\n",
      "       [    0.30866,     0.31235],\n",
      "       [    0.41592,     0.37528],\n",
      "       [    0.42722,     0.51461],\n",
      "       [    0.37077,     0.48989],\n",
      "       [    0.35947,     0.53034],\n",
      "       [    0.36887,      0.5573],\n",
      "       [    0.42534,     0.57754],\n",
      "       [    0.42909,     0.60224],\n",
      "       [    0.39898,     0.64271],\n",
      "       [    0.44416,     0.70112],\n",
      "       [    0.54578,     0.74606],\n",
      "       [    0.56272,     0.84045],\n",
      "       [    0.51944,     0.85618],\n",
      "       [    0.48556,     0.82696],\n",
      "       [     0.4705,     0.83145],\n",
      "       [    0.40275,     0.75506],\n",
      "       [    0.40088,     0.98202]], dtype=float32)], 'keypoints': array([[[    0.69844,       0.375,           2],\n",
      "        [    0.72656,     0.34888,           2],\n",
      "        [    0.69844,     0.33395,           2],\n",
      "        [    0.80156,     0.34888,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.91094,     0.45709,           2],\n",
      "        [    0.74531,     0.45895,           2],\n",
      "        [    0.75313,     0.66418,           2],\n",
      "        [    0.61875,     0.66605,           2],\n",
      "        [    0.60625,     0.53358,           2],\n",
      "        [    0.46875,      0.6791,           2],\n",
      "        [    0.87969,     0.91791,           2],\n",
      "        [    0.74219,      0.9347,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[    0.26094,      0.1847,           2],\n",
      "        [    0.28438,     0.15672,           2],\n",
      "        [    0.23438,     0.15299,           2],\n",
      "        [      0.325,     0.19403,           2],\n",
      "        [     0.1875,     0.17724,           2],\n",
      "        [    0.38281,     0.39552,           2],\n",
      "        [        0.1,     0.37873,           2],\n",
      "        [    0.40156,     0.59888,           2],\n",
      "        [   0.051562,     0.66045,           2],\n",
      "        [    0.47188,     0.73507,           2],\n",
      "        [    0.24062,     0.65858,           2],\n",
      "        [    0.34844,     0.90672,           2],\n",
      "        [    0.15781,     0.91418,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\val\\\\000000000192.jpg', 'shape': (480, 640), 'cls': array([[          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0]], dtype=float32), 'bboxes': array([[    0.64887,      0.7573,     0.20562,     0.45844],\n",
      "       [     0.7444,     0.71322,     0.12252,     0.51673],\n",
      "       [   0.029992,     0.78539,    0.057078,     0.42815],\n",
      "       [    0.50591,     0.61937,     0.17398,       0.491]], dtype=float32), 'segments': [array([[    0.56966,     0.98652],\n",
      "       [    0.59494,     0.86067],\n",
      "       [    0.58145,     0.81348],\n",
      "       [    0.59831,     0.75056],\n",
      "       [    0.54606,     0.68315],\n",
      "       [    0.59158,     0.61123],\n",
      "       [    0.63877,     0.60225],\n",
      "       [    0.63034,     0.55056],\n",
      "       [    0.66742,     0.52808],\n",
      "       [    0.69102,     0.54381],\n",
      "       [    0.68933,     0.57304],\n",
      "       [    0.68427,     0.60675],\n",
      "       [    0.72809,     0.64944],\n",
      "       [    0.75169,     0.74158],\n",
      "       [    0.70281,     0.79775],\n",
      "       [    0.70955,     0.84269],\n",
      "       [    0.68595,     0.87865],\n",
      "       [    0.66909,     0.98202]], dtype=float32), array([[    0.70166,     0.79179],\n",
      "       [    0.70444,     0.79017],\n",
      "       [    0.71463,     0.77987],\n",
      "       [    0.73777,     0.75806],\n",
      "       [    0.75042,     0.73915],\n",
      "       [    0.75042,     0.73008],\n",
      "       [    0.75197,     0.72598],\n",
      "       [    0.74116,     0.70871],\n",
      "       [    0.73808,     0.69719],\n",
      "       [    0.72973,     0.68196],\n",
      "       [    0.73005,     0.66056],\n",
      "       [    0.72387,     0.64371],\n",
      "       [     0.7103,      0.6326],\n",
      "       [    0.69672,      0.6219],\n",
      "       [      0.685,     0.61656],\n",
      "       [    0.68377,     0.60215],\n",
      "       [    0.68314,     0.60296],\n",
      "       [    0.68777,     0.58115],\n",
      "       [    0.69488,     0.56756],\n",
      "       [    0.70073,      0.5581],\n",
      "       [    0.69919,     0.54948],\n",
      "       [    0.70536,     0.53919],\n",
      "       [     0.7177,     0.53715],\n",
      "       [     0.7245,     0.53056],\n",
      "       [    0.72264,      0.5215],\n",
      "       [    0.71739,     0.51121],\n",
      "       [    0.71216,     0.50342],\n",
      "       [    0.71122,     0.49067],\n",
      "       [    0.71122,     0.48573],\n",
      "       [     0.7177,     0.48037],\n",
      "       [    0.71863,     0.47256],\n",
      "       [    0.72295,     0.46637],\n",
      "       [    0.72758,     0.46721],\n",
      "       [    0.73498,     0.45733],\n",
      "       [    0.74609,     0.45485],\n",
      "       [    0.75166,     0.45485],\n",
      "       [    0.75967,     0.46062],\n",
      "       [      0.764,     0.46844],\n",
      "       [    0.76616,     0.47296],\n",
      "       [    0.77387,     0.47873],\n",
      "       [    0.77542,     0.48367],\n",
      "       [    0.77078,     0.49312],\n",
      "       [    0.77109,     0.50219],\n",
      "       [    0.77202,     0.51081],\n",
      "       [    0.77141,     0.52233],\n",
      "       [    0.76555,     0.52975],\n",
      "       [    0.77789,     0.53469],\n",
      "       [    0.78498,     0.54127],\n",
      "       [    0.79517,     0.54577],\n",
      "       [    0.80319,     0.56717],\n",
      "       [    0.80566,     0.58733],\n",
      "       [    0.80041,     0.60298],\n",
      "       [    0.79486,     0.61037],\n",
      "       [    0.78992,     0.61696],\n",
      "       [    0.78406,     0.61615],\n",
      "       [    0.78312,     0.62644],\n",
      "       [    0.77695,     0.63096],\n",
      "       [    0.77542,     0.63177],\n",
      "       [    0.77387,     0.63752],\n",
      "       [    0.77942,     0.65275],\n",
      "       [    0.78005,     0.67044],\n",
      "       [    0.78005,     0.67415],\n",
      "       [    0.77387,     0.68031],\n",
      "       [     0.7785,     0.69306],\n",
      "       [    0.77912,     0.70004],\n",
      "       [    0.77819,      0.7161],\n",
      "       [    0.77819,     0.72844],\n",
      "       [    0.78066,     0.73173],\n",
      "       [    0.77973,     0.74077],\n",
      "       [     0.7785,     0.74365],\n",
      "       [    0.78159,     0.75023],\n",
      "       [    0.78344,     0.76135],\n",
      "       [    0.77356,     0.78685],\n",
      "       [    0.77727,     0.79054],\n",
      "       [     0.7822,     0.80494],\n",
      "       [    0.78344,     0.81194],\n",
      "       [    0.78498,     0.82469],\n",
      "       [    0.78622,     0.83087],\n",
      "       [    0.79023,     0.84115],\n",
      "       [    0.79023,     0.85431],\n",
      "       [    0.79084,      0.8646],\n",
      "       [    0.78961,     0.87158],\n",
      "       [     0.7893,     0.87777],\n",
      "       [    0.78869,      0.8975],\n",
      "       [    0.79177,     0.90902],\n",
      "       [    0.79239,     0.91767],\n",
      "       [    0.79147,       0.923],\n",
      "       [     0.7927,     0.92958],\n",
      "       [    0.79362,     0.93413],\n",
      "       [     0.7967,     0.93371],\n",
      "       [      0.793,     0.94317],\n",
      "       [    0.79023,      0.9481],\n",
      "       [    0.78777,     0.95017],\n",
      "       [    0.78406,     0.95469],\n",
      "       [    0.77758,     0.95881],\n",
      "       [      0.764,     0.96085],\n",
      "       [    0.76061,     0.94194],\n",
      "       [     0.7603,     0.93371],\n",
      "       [    0.75844,     0.92219],\n",
      "       [     0.7603,     0.89998],\n",
      "       [    0.75691,       0.886],\n",
      "       [    0.74672,     0.85637],\n",
      "       [    0.74672,      0.8786],\n",
      "       [    0.74394,     0.90494],\n",
      "       [    0.74672,      0.9144],\n",
      "       [    0.74795,     0.92304],\n",
      "       [    0.74733,     0.94235],\n",
      "       [    0.74856,     0.95965],\n",
      "       [    0.74764,     0.96746],\n",
      "       [    0.73438,     0.97075],\n",
      "       [    0.72913,     0.97158],\n",
      "       [    0.71894,     0.96129],\n",
      "       [    0.70289,     0.95881],\n",
      "       [    0.69055,     0.94442],\n",
      "       [    0.68747,     0.93331],\n",
      "       [    0.69548,     0.92631],\n",
      "       [    0.70906,     0.92344],\n",
      "       [    0.71184,     0.91602],\n",
      "       [    0.70197,     0.85556],\n",
      "       [    0.70381,     0.81073],\n",
      "       [    0.70166,     0.79179],\n",
      "       [     0.6973,     0.77471],\n",
      "       [    0.70316,     0.76648],\n",
      "       [    0.71891,     0.74631],\n",
      "       [    0.71798,     0.73315],\n",
      "       [    0.71828,      0.7245],\n",
      "       [    0.71767,      0.7175],\n",
      "       [     0.7118,      0.7101],\n",
      "       [    0.70533,     0.70969],\n",
      "       [    0.70378,     0.71421],\n",
      "       [     0.7047,       0.713],\n",
      "       [    0.70286,     0.74921],\n",
      "       [    0.69761,     0.76113],\n",
      "       [    0.68834,     0.77017],\n",
      "       [    0.69144,     0.77471],\n",
      "       [     0.6973,     0.77471]], dtype=float32), array([[   0.012875,     0.57131],\n",
      "       [   0.031422,     0.58273],\n",
      "       [   0.035703,     0.59606],\n",
      "       [       0.03,      0.6246],\n",
      "       [   0.025719,     0.63602],\n",
      "       [   0.021437,     0.64173],\n",
      "       [   0.017156,     0.64744],\n",
      "       [   0.047125,     0.69881],\n",
      "       [   0.055687,     0.75969],\n",
      "       [   0.058531,     0.76731],\n",
      "       [   0.055687,     0.79965],\n",
      "       [    0.05425,     0.81869],\n",
      "       [   0.048547,     0.84913],\n",
      "       [   0.047125,     0.87006],\n",
      "       [   0.041406,     0.87388],\n",
      "       [   0.032844,     0.87196],\n",
      "       [       0.03,     0.86435],\n",
      "       [   0.027141,     0.86625],\n",
      "       [   0.018578,     0.95569],\n",
      "       [   0.011437,     0.97663],\n",
      "       [  0.0071563,     0.99375],\n",
      "       [  0.0057344,     0.99946],\n",
      "       [   0.002875,     0.99946],\n",
      "       [  0.0014531,     0.57131]], dtype=float32), array([[    0.57095,     0.81756],\n",
      "       [     0.5473,     0.81531],\n",
      "       [    0.54392,     0.84685],\n",
      "       [    0.53884,     0.86488],\n",
      "       [    0.51689,      0.8626],\n",
      "       [    0.50675,     0.83333],\n",
      "       [    0.50675,     0.80406],\n",
      "       [     0.4848,     0.69144],\n",
      "       [    0.46453,     0.64415],\n",
      "       [     0.4527,     0.57883],\n",
      "       [     0.4375,     0.55406],\n",
      "       [    0.41892,     0.52477],\n",
      "       [     0.4223,       0.491],\n",
      "       [    0.45608,     0.43469],\n",
      "       [    0.47466,     0.41892],\n",
      "       [    0.48648,     0.40315],\n",
      "       [    0.49325,     0.38287],\n",
      "       [    0.50675,     0.37387],\n",
      "       [    0.52872,     0.37837],\n",
      "       [    0.53884,     0.38965],\n",
      "       [    0.54223,     0.40992],\n",
      "       [     0.5625,     0.42117],\n",
      "       [     0.5777,     0.43469],\n",
      "       [    0.58953,     0.45946],\n",
      "       [    0.59291,     0.48198],\n",
      "       [    0.59291,     0.50675],\n",
      "       [    0.58953,     0.53379],\n",
      "       [    0.58953,     0.55856],\n",
      "       [    0.58784,     0.57433],\n",
      "       [    0.58108,     0.58108],\n",
      "       [     0.5625,     0.57883],\n",
      "       [    0.55913,      0.6081],\n",
      "       [    0.55913,     0.63965],\n",
      "       [    0.55913,     0.67117],\n",
      "       [    0.55744,     0.69144],\n",
      "       [    0.55744,     0.71396],\n",
      "       [    0.55405,     0.73423],\n",
      "       [    0.55067,     0.75675],\n",
      "       [    0.55913,     0.77027],\n",
      "       [    0.57433,     0.77702],\n",
      "       [    0.58445,     0.78604]], dtype=float32)], 'keypoints': array([[[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [    0.63906,     0.58542,           2],\n",
      "        [      0.675,     0.59167,           2],\n",
      "        [    0.61094,     0.62708,           2],\n",
      "        [    0.70156,        0.65,           2],\n",
      "        [    0.55469,     0.69375,           2],\n",
      "        [    0.72812,     0.72917,           2],\n",
      "        [    0.59062,     0.73125,           2],\n",
      "        [    0.69844,       0.775,           2],\n",
      "        [    0.61406,     0.79583,           2],\n",
      "        [    0.66562,     0.80625,           2],\n",
      "        [    0.60156,     0.91667,           2],\n",
      "        [    0.65625,     0.93333,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [      0.725,     0.50417,           2],\n",
      "        [          0,           0,           0],\n",
      "        [     0.7125,     0.57083,           2],\n",
      "        [    0.78438,      0.5625,           2],\n",
      "        [    0.68906,     0.63542,           1],\n",
      "        [    0.78906,     0.60417,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [    0.71719,         0.7,           1],\n",
      "        [     0.7625,     0.69792,           2],\n",
      "        [    0.72344,     0.83125,           2],\n",
      "        [    0.76406,      0.8125,           2],\n",
      "        [    0.72656,     0.93958,           2],\n",
      "        [    0.77656,      0.9375,           2]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [   0.020313,     0.61875,           2],\n",
      "        [          0,           0,           0],\n",
      "        [   0.026562,     0.68958,           2],\n",
      "        [          0,           0,           0],\n",
      "        [   0.045312,      0.7875,           2],\n",
      "        [          0,           0,           0],\n",
      "        [   0.045312,     0.83125,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[    0.51094,        0.45,           2],\n",
      "        [    0.51719,     0.43958,           2],\n",
      "        [    0.50313,     0.43958,           2],\n",
      "        [    0.52656,     0.42917,           2],\n",
      "        [    0.49062,     0.42917,           2],\n",
      "        [       0.55,     0.44792,           2],\n",
      "        [    0.45625,     0.47083,           2],\n",
      "        [    0.57031,     0.49167,           2],\n",
      "        [    0.43437,     0.52292,           2],\n",
      "        [    0.57344,     0.54167,           2],\n",
      "        [     0.4625,     0.57083,           2],\n",
      "        [    0.53125,     0.58958,           2],\n",
      "        [     0.4875,         0.6,           2],\n",
      "        [     0.5375,     0.69792,           2],\n",
      "        [    0.51562,     0.70625,           2],\n",
      "        [    0.54219,     0.78333,           2],\n",
      "        [    0.52812,      0.8375,           2]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\val\\\\000000000241.jpg', 'shape': (640, 480), 'cls': array([[          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0]], dtype=float32), 'bboxes': array([[    0.48524,     0.49946,     0.41756,     0.97839],\n",
      "       [    0.21723,     0.68371,     0.42846,     0.54383],\n",
      "       [    0.72768,     0.61193,     0.22323,      0.4018],\n",
      "       [   0.047031,      0.7413,    0.094062,     0.31778],\n",
      "       [    0.91199,     0.70787,     0.17602,     0.35955]], dtype=float32), 'segments': [array([[    0.54427,    0.027531],\n",
      "       [    0.57019,    0.055609],\n",
      "       [    0.57308,    0.096656],\n",
      "       [    0.53565,     0.14417],\n",
      "       [    0.57883,     0.17225],\n",
      "       [     0.6134,     0.17656],\n",
      "       [    0.64219,     0.20464],\n",
      "       [    0.69402,     0.29103],\n",
      "       [    0.68537,     0.37959],\n",
      "       [    0.67387,     0.44222],\n",
      "       [    0.67387,      0.5243],\n",
      "       [    0.63644,     0.58694],\n",
      "       [    0.62202,     0.65389],\n",
      "       [    0.61627,     0.72733],\n",
      "       [    0.61915,      0.8677],\n",
      "       [    0.60475,     0.95411],\n",
      "       [    0.56156,      0.9865],\n",
      "       [    0.49821,     0.98866],\n",
      "       [     0.5126,     0.95194],\n",
      "       [    0.51835,     0.92386],\n",
      "       [    0.50396,     0.91955],\n",
      "       [    0.44925,     0.93467],\n",
      "       [    0.41756,      0.9433],\n",
      "       [    0.35708,     0.95627],\n",
      "       [    0.34556,     0.94978],\n",
      "       [     0.3686,     0.91955],\n",
      "       [    0.42908,     0.86555],\n",
      "       [    0.41181,     0.77916],\n",
      "       [    0.37437,     0.64956],\n",
      "       [    0.35708,     0.57614],\n",
      "       [    0.35708,     0.54158],\n",
      "       [    0.35708,     0.50917],\n",
      "       [    0.32829,     0.50702],\n",
      "       [    0.29662,      0.5135],\n",
      "       [    0.27646,     0.50917],\n",
      "       [    0.31102,     0.46814],\n",
      "       [    0.31677,      0.4487],\n",
      "       [    0.34269,     0.38175],\n",
      "       [    0.35421,     0.30616],\n",
      "       [    0.42044,     0.21544],\n",
      "       [    0.44925,     0.16145],\n",
      "       [    0.41469,     0.16361],\n",
      "       [    0.38877,     0.14202],\n",
      "       [     0.3859,    0.077219],\n",
      "       [    0.39742,    0.027531],\n",
      "       [    0.50683,    0.010266]], dtype=float32), array([[   0.086896,      0.4882],\n",
      "       [   0.068917,     0.47697],\n",
      "       [   0.077896,     0.44775],\n",
      "       [   0.086896,     0.42978],\n",
      "       [    0.13183,      0.4118],\n",
      "       [    0.18577,     0.42528],\n",
      "       [    0.18877,      0.4455],\n",
      "       [    0.18277,     0.47697],\n",
      "       [    0.17677,     0.50169],\n",
      "       [    0.21273,     0.52416],\n",
      "       [    0.23371,     0.54663],\n",
      "       [    0.25769,     0.63427],\n",
      "       [     0.3176,     0.66798],\n",
      "       [    0.32658,     0.66798],\n",
      "       [    0.35656,     0.69944],\n",
      "       [    0.38052,     0.73989],\n",
      "       [    0.38352,     0.76686],\n",
      "       [    0.43146,     0.80506],\n",
      "       [    0.43146,     0.83427],\n",
      "       [    0.42248,     0.85898],\n",
      "       [     0.3955,     0.86123],\n",
      "       [    0.36554,      0.8545],\n",
      "       [    0.34756,     0.82303],\n",
      "       [    0.37752,     0.80955],\n",
      "       [    0.35656,     0.80056],\n",
      "       [     0.3086,     0.77809],\n",
      "       [    0.29963,     0.75786],\n",
      "       [    0.27865,     0.73539],\n",
      "       [    0.23371,     0.72416],\n",
      "       [    0.22173,     0.72416],\n",
      "       [    0.18877,     0.75112],\n",
      "       [    0.19175,     0.78483],\n",
      "       [    0.20075,     0.81405],\n",
      "       [    0.20075,     0.84775],\n",
      "       [    0.20973,     0.86798],\n",
      "       [    0.22473,      0.8927],\n",
      "       [    0.23671,     0.90619],\n",
      "       [    0.26367,     0.92641],\n",
      "       [    0.22473,     0.94437],\n",
      "       [    0.20375,     0.95562],\n",
      "       [    0.19175,     0.95562],\n",
      "       [    0.16479,     0.93539],\n",
      "       [    0.14981,     0.90842],\n",
      "       [    0.14981,     0.90169],\n",
      "       [    0.14381,      0.8882],\n",
      "       [    0.14981,     0.87472],\n",
      "       [    0.11685,     0.83652],\n",
      "       [    0.11385,     0.81855],\n",
      "       [    0.10787,     0.77809],\n",
      "       [    0.10187,     0.75337],\n",
      "       [   0.092875,     0.75337],\n",
      "       [   0.062917,     0.69944],\n",
      "       [   0.017979,     0.66798],\n",
      "       [      0.003,     0.63427],\n",
      "       [      0.006,     0.52866]], dtype=float32), array([[    0.61606,     0.81059],\n",
      "       [    0.64583,     0.81283],\n",
      "       [    0.64583,     0.81283],\n",
      "       [    0.70535,     0.68336],\n",
      "       [    0.79763,      0.6588],\n",
      "       [    0.79763,     0.65211],\n",
      "       [    0.83929,     0.51595],\n",
      "       [    0.81548,     0.48247],\n",
      "       [    0.78869,     0.46461],\n",
      "       [    0.78571,     0.44228],\n",
      "       [     0.7619,     0.41103],\n",
      "       [    0.73513,      0.4155],\n",
      "       [    0.70535,     0.42889],\n",
      "       [     0.6994,     0.48247],\n",
      "       [    0.66965,     0.50478],\n",
      "       [      0.625,     0.64317],\n",
      "       [      0.625,     0.80612]], dtype=float32), array([[   0.013208,     0.64891],\n",
      "       [   0.047125,     0.68022],\n",
      "       [   0.070583,     0.70662],\n",
      "       [   0.073208,     0.72619],\n",
      "       [   0.067979,      0.8015],\n",
      "       [   0.075813,       0.824],\n",
      "       [     0.0745,     0.85041],\n",
      "       [   0.094062,     0.87389],\n",
      "       [   0.088854,     0.89433],\n",
      "       [   0.071896,     0.90019],\n",
      "       [     0.0445,     0.88063],\n",
      "       [    0.02625,     0.87378],\n",
      "       [   0.021042,       0.864],\n",
      "       [   0.015812,     0.84542],\n",
      "       [  0.0027708,     0.84053],\n",
      "       [          0,     0.82977],\n",
      "       [  0.0040833,     0.67327],\n",
      "       [  0.0027708,     0.58241],\n",
      "       [  0.0092917,     0.59022],\n",
      "       [   0.014521,      0.6137]], dtype=float32), array([[          1,     0.64045],\n",
      "       [          1,     0.85619],\n",
      "       [          1,     0.85619],\n",
      "       [    0.97677,     0.88539],\n",
      "       [    0.93783,     0.88764],\n",
      "       [    0.92583,     0.86517],\n",
      "       [    0.97977,     0.82922],\n",
      "       [    0.98877,     0.81348],\n",
      "       [    0.98877,     0.78652],\n",
      "       [    0.98277,     0.76405],\n",
      "       [    0.97079,     0.75281],\n",
      "       [    0.97079,     0.72134],\n",
      "       [    0.96179,     0.71909],\n",
      "       [    0.94381,     0.71236],\n",
      "       [     0.8839,     0.70562],\n",
      "       [    0.85694,     0.70113],\n",
      "       [    0.83596,     0.68539],\n",
      "       [    0.82398,     0.67191],\n",
      "       [    0.82996,     0.65169],\n",
      "       [    0.85094,     0.63595],\n",
      "       [    0.89887,     0.64494],\n",
      "       [    0.94381,     0.65169],\n",
      "       [    0.98877,     0.64045],\n",
      "       [          1,     0.64045],\n",
      "       [          1,      0.5618],\n",
      "       [    0.97977,      0.5618],\n",
      "       [    0.97079,      0.5573],\n",
      "       [    0.97079,     0.54606],\n",
      "       [    0.97677,     0.52809],\n",
      "       [    0.98877,     0.52809],\n",
      "       [          1,      0.5618]], dtype=float32)], 'keypoints': array([[[    0.39583,     0.11094,           2],\n",
      "        [    0.42292,    0.092188,           2],\n",
      "        [     0.3875,    0.098437,           2],\n",
      "        [    0.50625,    0.098437,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.57917,     0.21875,           2],\n",
      "        [    0.41667,       0.225,           2],\n",
      "        [    0.63333,     0.38125,           2],\n",
      "        [    0.37708,     0.37031,           2],\n",
      "        [    0.57708,     0.53438,           2],\n",
      "        [    0.33125,     0.47344,           2],\n",
      "        [    0.52292,     0.53438,           2],\n",
      "        [    0.40625,     0.51875,           2],\n",
      "        [    0.53333,     0.77188,           2],\n",
      "        [    0.43333,     0.72656,           2],\n",
      "        [    0.57292,      0.9375,           2],\n",
      "        [    0.47708,         0.9,           2]],\n",
      "\n",
      "       [[    0.11042,      0.4625,           2],\n",
      "        [    0.13333,        0.45,           2],\n",
      "        [        0.1,     0.44688,           2],\n",
      "        [      0.175,     0.46094,           2],\n",
      "        [    0.08125,     0.45156,           2],\n",
      "        [    0.19792,     0.51719,           2],\n",
      "        [   0.047917,      0.5375,           2],\n",
      "        [     0.2375,     0.60312,           2],\n",
      "        [      0.075,     0.64531,           2],\n",
      "        [     0.2375,     0.67344,           2],\n",
      "        [    0.17708,      0.6875,           2],\n",
      "        [    0.18333,     0.64844,           2],\n",
      "        [   0.079167,     0.67031,           2],\n",
      "        [    0.31458,     0.68125,           2],\n",
      "        [    0.14375,     0.72188,           2],\n",
      "        [    0.37917,     0.81094,           2],\n",
      "        [    0.19167,     0.88437,           2]],\n",
      "\n",
      "       [[     0.7375,     0.46562,           2],\n",
      "        [       0.75,     0.45781,           2],\n",
      "        [      0.725,     0.45781,           2],\n",
      "        [    0.77917,     0.45469,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.79792,     0.51875,           2],\n",
      "        [    0.68542,     0.49687,           2],\n",
      "        [    0.79792,     0.59531,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.76667,     0.63437,           2],\n",
      "        [    0.63333,     0.53906,           1],\n",
      "        [    0.73125,     0.61875,           2],\n",
      "        [    0.66042,     0.60469,           2],\n",
      "        [    0.64792,     0.64062,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.62292,     0.78125,           1],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [   0.052083,     0.70625,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.04375,     0.84375,           2],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [     0.9875,     0.54531,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [    0.83958,     0.64531,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.98333,     0.69531,           2]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\val\\\\000000000294.jpg', 'shape': (427, 640), 'cls': array([[          0]], dtype=float32), 'bboxes': array([[    0.32837,     0.58177,     0.57017,     0.83646]], dtype=float32), 'segments': [array([[   0.043281,     0.99126],\n",
      "       [   0.043281,     0.87269],\n",
      "       [   0.046266,      0.8123],\n",
      "       [   0.047766,     0.61991],\n",
      "       [   0.076125,     0.48119],\n",
      "       [   0.092547,     0.42974],\n",
      "       [    0.16567,     0.36262],\n",
      "       [    0.15822,     0.29328],\n",
      "       [    0.16269,     0.27091],\n",
      "       [    0.17016,     0.20604],\n",
      "       [    0.18209,     0.17023],\n",
      "       [    0.24031,     0.16354],\n",
      "       [    0.27166,     0.19485],\n",
      "       [    0.28956,      0.2351],\n",
      "       [    0.28658,     0.28208],\n",
      "       [    0.28956,     0.34026],\n",
      "       [     0.2597,     0.41632],\n",
      "       [    0.25672,      0.4633],\n",
      "       [    0.32539,     0.54159],\n",
      "       [    0.34478,     0.58187],\n",
      "       [    0.43883,     0.46777],\n",
      "       [    0.41345,     0.41407],\n",
      "       [    0.42241,     0.39618],\n",
      "       [    0.47166,     0.32909],\n",
      "       [    0.48509,     0.35368],\n",
      "       [    0.48211,     0.43646],\n",
      "       [     0.4642,     0.50806],\n",
      "       [    0.42389,      0.6378],\n",
      "       [    0.38808,     0.70044],\n",
      "       [    0.34927,     0.70714],\n",
      "       [    0.37016,     0.76309],\n",
      "       [    0.50748,     0.75859],\n",
      "       [    0.55227,     0.74295],\n",
      "       [     0.5642,     0.71609],\n",
      "       [    0.61345,     0.74518],\n",
      "       [    0.60748,     0.77426],\n",
      "       [    0.57017,     0.81677],\n",
      "       [    0.47763,     0.82349],\n",
      "       [    0.35673,     0.85927],\n",
      "       [    0.36419,     0.99799],\n",
      "       [   0.044781,           1]], dtype=float32)], 'keypoints': array([[[    0.23281,     0.31148,           2],\n",
      "        [    0.24844,     0.27869,           2],\n",
      "        [    0.20625,     0.27869,           2],\n",
      "        [    0.28125,     0.30211,           2],\n",
      "        [    0.16875,     0.30913,           2],\n",
      "        [    0.27187,     0.52459,           2],\n",
      "        [    0.17812,     0.45902,           2],\n",
      "        [    0.35313,     0.82201,           2],\n",
      "        [    0.37187,     0.65574,           2],\n",
      "        [    0.50625,     0.78923,           2],\n",
      "        [     0.4375,     0.49883,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}, {'im_file': 'C:\\\\Users\\\\nikhi\\\\Desktop\\\\Mini-COCO\\\\images\\\\val\\\\000000000308.jpg', 'shape': (426, 640), 'cls': array([[          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0],\n",
      "       [          0]], dtype=float32), 'bboxes': array([[    0.31491,     0.53139,     0.20894,     0.92826],\n",
      "       [    0.14459,     0.55553,     0.28919,     0.88894],\n",
      "       [    0.19879,     0.34809,     0.25464,     0.62415],\n",
      "       [    0.20068,     0.28793,    0.053922,      0.2061],\n",
      "       [     0.7328,     0.51985,     0.27469,     0.92951],\n",
      "       [   0.093484,      0.7719,     0.18697,     0.43371],\n",
      "       [    0.57929,      0.3785,    0.077953,      0.4138]], dtype=float32), 'segments': [array([[    0.34625,     0.90359],\n",
      "       [    0.34625,     0.93498],\n",
      "       [     0.3537,     0.96413],\n",
      "       [     0.3552,     0.97533],\n",
      "       [     0.3552,      0.9843],\n",
      "       [    0.34028,     0.98655],\n",
      "       [    0.31938,     0.98878],\n",
      "       [      0.297,     0.99552],\n",
      "       [    0.28953,     0.96413],\n",
      "       [    0.28356,     0.90582],\n",
      "       [    0.28058,     0.82063],\n",
      "       [    0.28356,     0.77129],\n",
      "       [    0.28655,     0.73991],\n",
      "       [    0.28356,     0.71749],\n",
      "       [    0.28058,     0.70852],\n",
      "       [    0.28356,      0.6704],\n",
      "       [    0.28655,     0.61434],\n",
      "       [    0.30894,     0.56951],\n",
      "       [    0.31639,      0.5269],\n",
      "       [    0.31042,     0.46188],\n",
      "       [    0.30744,      0.4462],\n",
      "       [    0.29998,     0.40808],\n",
      "       [    0.28356,     0.37221],\n",
      "       [    0.26416,     0.34754],\n",
      "       [    0.24923,     0.34977],\n",
      "       [    0.23281,     0.38117],\n",
      "       [    0.21491,     0.40134],\n",
      "       [    0.21491,     0.36324],\n",
      "       [    0.21044,     0.32735],\n",
      "       [    0.21044,     0.30045],\n",
      "       [    0.22238,     0.27354],\n",
      "       [    0.22834,     0.26458],\n",
      "       [     0.2567,     0.23542],\n",
      "       [    0.28805,     0.19507],\n",
      "       [    0.28655,     0.18385],\n",
      "       [    0.28058,     0.16591],\n",
      "       [    0.27759,     0.13676],\n",
      "       [    0.27908,     0.11883],\n",
      "       [    0.28505,    0.091925],\n",
      "       [      0.297,    0.071761],\n",
      "       [     0.3373,    0.067254],\n",
      "       [    0.34625,    0.085211],\n",
      "       [    0.34625,     0.12108],\n",
      "       [    0.35222,     0.22646],\n",
      "       [    0.34923,     0.23768],\n",
      "       [    0.35072,     0.23768],\n",
      "       [    0.37609,     0.25336],\n",
      "       [    0.37908,     0.27129],\n",
      "       [    0.38953,     0.28925],\n",
      "       [    0.39102,     0.30718],\n",
      "       [      0.394,     0.32512],\n",
      "       [      0.394,     0.33183],\n",
      "       [    0.39848,     0.34528],\n",
      "       [    0.41341,     0.37221],\n",
      "       [    0.41938,     0.45965],\n",
      "       [    0.41191,     0.49326],\n",
      "       [    0.40594,     0.53364],\n",
      "       [    0.40147,     0.56951],\n",
      "       [    0.40744,     0.60089],\n",
      "       [    0.40892,     0.62331],\n",
      "       [    0.39102,     0.63005],\n",
      "       [    0.37012,     0.64124],\n",
      "       [    0.36416,      0.6592],\n",
      "       [    0.34028,      0.6861],\n",
      "       [    0.33131,     0.69955],\n",
      "       [    0.33431,     0.73542],\n",
      "       [    0.33878,     0.77355],\n",
      "       [    0.34028,      0.8565],\n",
      "       [    0.34625,     0.90359],\n",
      "       [    0.36266,     0.91031],\n",
      "       [    0.37459,     0.94843],\n",
      "       [    0.38356,      0.9462],\n",
      "       [    0.39102,     0.93946],\n",
      "       [    0.39997,     0.91031],\n",
      "       [    0.39997,     0.86099],\n",
      "       [     0.3955,     0.82286],\n",
      "       [      0.394,     0.81167],\n",
      "       [    0.37609,     0.79596],\n",
      "       [    0.36714,     0.80045],\n",
      "       [    0.36564,     0.83408],\n",
      "       [    0.36266,     0.87221],\n",
      "       [    0.36266,     0.91031]], dtype=float32), array([[  0.0034844,     0.12005],\n",
      "       [   0.037891,     0.11106],\n",
      "       [    0.08725,     0.12678],\n",
      "       [    0.12166,     0.15376],\n",
      "       [    0.14409,     0.21444],\n",
      "       [    0.14559,     0.24364],\n",
      "       [    0.12316,     0.24589],\n",
      "       [    0.12316,     0.26613],\n",
      "       [    0.12764,     0.28409],\n",
      "       [    0.11567,     0.31556],\n",
      "       [   0.099219,     0.33352],\n",
      "       [   0.091734,     0.36948],\n",
      "       [   0.079781,     0.38972],\n",
      "       [   0.073797,     0.40319],\n",
      "       [    0.11417,     0.43916],\n",
      "       [    0.14409,     0.50207],\n",
      "       [    0.16055,     0.59195],\n",
      "       [    0.18298,     0.57847],\n",
      "       [    0.22636,     0.52005],\n",
      "       [    0.25628,     0.49758],\n",
      "       [    0.27872,     0.49758],\n",
      "       [    0.28919,     0.53352],\n",
      "       [    0.28619,     0.55824],\n",
      "       [    0.27423,     0.58073],\n",
      "       [    0.26227,     0.59195],\n",
      "       [    0.22636,     0.61218],\n",
      "       [    0.20094,     0.65937],\n",
      "       [    0.19645,     0.69308],\n",
      "       [    0.19645,     0.72904],\n",
      "       [    0.19195,     0.75824],\n",
      "       [    0.20542,     0.83465],\n",
      "       [    0.19944,     0.86613],\n",
      "       [    0.18747,      0.9088],\n",
      "       [    0.18448,      0.9515],\n",
      "       [    0.20392,           1],\n",
      "       [   0.028922,           1],\n",
      "       [   0.075281,     0.94028],\n",
      "       [   0.094734,      0.9088],\n",
      "       [    0.11867,      0.8796],\n",
      "       [    0.13961,     0.86836],\n",
      "       [     0.1755,     0.84141],\n",
      "       [    0.18897,     0.81892],\n",
      "       [    0.18148,      0.7942],\n",
      "       [    0.18148,     0.77847],\n",
      "       [      0.177,     0.77174],\n",
      "       [       0.18,     0.74927],\n",
      "       [    0.18897,      0.7223],\n",
      "       [    0.18448,     0.70657],\n",
      "       [    0.15456,     0.71556],\n",
      "       [    0.13961,     0.70657],\n",
      "       [    0.08875,     0.76723],\n",
      "       [      0.002,     0.89981],\n",
      "       [      0.002,      0.6796],\n",
      "       [   0.031906,     0.64141],\n",
      "       [   0.061828,      0.6369],\n",
      "       [   0.081266,     0.63016],\n",
      "       [   0.076781,     0.61218],\n",
      "       [   0.072297,     0.58521],\n",
      "       [   0.064812,     0.56049],\n",
      "       [   0.078281,     0.52678],\n",
      "       [   0.072297,     0.47061],\n",
      "       [   0.051359,     0.41667],\n",
      "       [   0.028922,      0.4077],\n",
      "       [      0.002,     0.41218],\n",
      "       [          0,     0.36948],\n",
      "       [          0,     0.28859],\n",
      "       [  0.0049844,     0.12904]], dtype=float32), array([[   0.096797,     0.12549],\n",
      "       [   0.096797,     0.11432],\n",
      "       [   0.071469,    0.096409],\n",
      "       [   0.099766,     0.10089],\n",
      "       [    0.10423,    0.036009],\n",
      "       [     0.1772,    0.049437],\n",
      "       [    0.19508,     0.11878],\n",
      "       [    0.21294,     0.13892],\n",
      "       [    0.19061,     0.15235],\n",
      "       [    0.18167,     0.19038],\n",
      "       [    0.17572,     0.21498],\n",
      "       [     0.1638,     0.23289],\n",
      "       [    0.16231,      0.2396],\n",
      "       [    0.21442,     0.39394],\n",
      "       [    0.22039,     0.38948],\n",
      "       [    0.26655,     0.34697],\n",
      "       [    0.29334,      0.3962],\n",
      "       [    0.32611,     0.51477],\n",
      "       [    0.29334,     0.60871],\n",
      "       [    0.28739,     0.66016],\n",
      "       [    0.25166,     0.60425],\n",
      "       [    0.28739,     0.56622],\n",
      "       [    0.28739,     0.51028],\n",
      "       [    0.26506,     0.49911],\n",
      "       [    0.16083,     0.58859],\n",
      "       [    0.14444,     0.47897],\n",
      "       [   0.081906,     0.40514],\n",
      "       [    0.12955,     0.30671],\n",
      "       [    0.13402,     0.24855],\n",
      "       [    0.15041,     0.24855],\n",
      "       [    0.14147,     0.19038],\n",
      "       [    0.12211,     0.15458]], dtype=float32), array([[    0.17372,     0.27488],\n",
      "       [    0.21447,     0.39099],\n",
      "       [    0.21327,     0.34688],\n",
      "       [    0.21027,     0.30458],\n",
      "       [    0.22105,     0.27669],\n",
      "       [    0.21386,     0.26857],\n",
      "       [    0.22105,     0.26498],\n",
      "       [    0.22644,     0.21277],\n",
      "       [    0.22764,     0.20197],\n",
      "       [    0.21806,     0.19298],\n",
      "       [    0.20367,     0.18488],\n",
      "       [     0.1935,     0.18488],\n",
      "       [     0.1857,     0.19117],\n",
      "       [    0.17911,     0.20378],\n",
      "       [    0.17852,     0.20648],\n",
      "       [    0.18031,     0.22448],\n",
      "       [    0.18391,     0.24878],\n",
      "       [     0.1857,     0.25777],\n",
      "       [    0.18211,     0.26498],\n",
      "       [    0.17731,     0.27127],\n",
      "       [    0.17613,     0.27218],\n",
      "       [    0.17552,     0.27399]], dtype=float32), array([[    0.70153,     0.97645],\n",
      "       [    0.69337,     0.78441],\n",
      "       [    0.73416,     0.70066],\n",
      "       [      0.726,     0.65775],\n",
      "       [    0.70697,     0.61077],\n",
      "       [    0.68112,     0.62711],\n",
      "       [    0.67161,     0.64754],\n",
      "       [    0.64305,     0.64958],\n",
      "       [    0.63355,     0.64141],\n",
      "       [    0.64305,     0.59033],\n",
      "       [    0.68928,     0.55357],\n",
      "       [    0.70697,     0.47798],\n",
      "       [    0.64033,     0.48411],\n",
      "       [    0.60633,     0.51883],\n",
      "       [    0.59545,     0.50657],\n",
      "       [    0.60091,     0.47183],\n",
      "       [    0.60227,     0.45141],\n",
      "       [    0.69744,      0.3881],\n",
      "       [    0.73416,     0.29411],\n",
      "       [     0.6988,     0.22873],\n",
      "       [    0.70153,     0.21855],\n",
      "       [    0.65938,     0.20831],\n",
      "       [    0.68248,     0.16542],\n",
      "       [    0.68792,     0.08777],\n",
      "       [    0.76272,    0.055094],\n",
      "       [    0.78991,    0.079624],\n",
      "       [    0.80623,     0.12251],\n",
      "       [      0.828,     0.13476],\n",
      "       [    0.80214,     0.18789],\n",
      "       [    0.87014,     0.33089],\n",
      "       [    0.85111,     0.53315],\n",
      "       [    0.83342,     0.58624],\n",
      "       [    0.84838,     0.79462],\n",
      "       [    0.80488,      0.9846],\n",
      "       [    0.70425,     0.98258]], dtype=float32), array([[    0.12266,     0.71911],\n",
      "       [    0.14509,     0.70786],\n",
      "       [    0.16005,      0.7146],\n",
      "       [    0.18697,     0.71012],\n",
      "       [    0.18248,     0.75056],\n",
      "       [    0.18548,     0.82472],\n",
      "       [    0.16155,     0.85617],\n",
      "       [    0.12266,     0.87641],\n",
      "       [   0.040391,     0.98876],\n",
      "       [          0,     0.98653],\n",
      "       [     0.0015,     0.90786],\n",
      "       [    0.12266,     0.71911],\n",
      "       [   0.079281,     0.63146],\n",
      "       [   0.034406,     0.64495],\n",
      "       [          0,     0.68089],\n",
      "       [          0,     0.55955],\n",
      "       [   0.025422,     0.55505],\n",
      "       [   0.058328,     0.56181],\n",
      "       [   0.071797,     0.59552],\n",
      "       [   0.079281,     0.63146]], dtype=float32), array([[    0.58578,      0.1716],\n",
      "       [    0.58383,     0.25747],\n",
      "       [    0.59098,     0.34824],\n",
      "       [    0.59747,     0.37751],\n",
      "       [    0.61827,     0.38826],\n",
      "       [    0.61567,     0.39704],\n",
      "       [    0.59033,     0.39704],\n",
      "       [    0.57148,     0.40876],\n",
      "       [    0.56305,     0.41655],\n",
      "       [    0.56434,     0.42533],\n",
      "       [    0.57734,     0.43509],\n",
      "       [    0.58969,     0.43901],\n",
      "       [    0.58969,     0.45462],\n",
      "       [    0.58708,     0.44974],\n",
      "       [    0.58708,     0.47707],\n",
      "       [    0.58189,     0.50927],\n",
      "       [    0.58253,     0.52392],\n",
      "       [     0.5728,     0.52878],\n",
      "       [    0.57084,     0.56979],\n",
      "       [     0.5728,      0.5854],\n",
      "       [    0.56434,     0.58441],\n",
      "       [    0.56434,     0.53758],\n",
      "       [    0.56175,     0.50146],\n",
      "       [     0.5533,     0.42437],\n",
      "       [    0.54486,     0.39998],\n",
      "       [    0.54486,     0.38143],\n",
      "       [    0.54031,     0.35815],\n",
      "       [    0.54031,     0.32498],\n",
      "       [    0.54486,     0.28885],\n",
      "       [    0.55266,     0.25763],\n",
      "       [    0.55591,      0.2469],\n",
      "       [    0.56564,     0.23519],\n",
      "       [    0.56109,     0.21577],\n",
      "       [    0.56175,     0.19723],\n",
      "       [    0.56564,     0.18648],\n",
      "       [    0.56759,     0.17674],\n",
      "       [    0.57344,     0.17282]], dtype=float32)], 'keypoints': array([[[    0.32656,     0.19249,           2],\n",
      "        [    0.33906,     0.17371,           2],\n",
      "        [    0.30937,     0.17136,           2],\n",
      "        [    0.34375,     0.15023,           2],\n",
      "        [    0.28125,     0.15962,           2],\n",
      "        [    0.35469,       0.277,           2],\n",
      "        [     0.2375,     0.28873,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.24844,     0.45775,           1],\n",
      "        [          0,           0,           0],\n",
      "        [      0.325,     0.46009,           2],\n",
      "        [    0.36719,     0.57512,           2],\n",
      "        [    0.29688,     0.59624,           2],\n",
      "        [    0.39375,     0.75117,           1],\n",
      "        [    0.30469,     0.81221,           2],\n",
      "        [    0.39062,     0.89437,           2],\n",
      "        [     0.3125,     0.99061,           2]],\n",
      "\n",
      "       [[    0.08125,      0.3169,           2],\n",
      "        [   0.098437,     0.28873,           2],\n",
      "        [   0.053125,     0.27934,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [   0.017188,     0.49061,           1],\n",
      "        [          0,           0,           0],\n",
      "        [   0.067187,     0.77934,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.20156,      0.5892,           2],\n",
      "        [          0,           0,           0],\n",
      "        [   0.092188,     0.94836,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[    0.17969,     0.17606,           2],\n",
      "        [    0.18281,     0.15023,           2],\n",
      "        [    0.16563,     0.14789,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.11094,     0.13615,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.08125,     0.33099,           1],\n",
      "        [          0,           0,           0],\n",
      "        [    0.11719,     0.53052,           1],\n",
      "        [          0,           0,           0],\n",
      "        [    0.21094,     0.62207,           1],\n",
      "        [          0,           0,           0],\n",
      "        [    0.14062,     0.64319,           1],\n",
      "        [          0,           0,           0],\n",
      "        [     0.1375,     0.91549,           1],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[    0.22187,     0.23005,           2],\n",
      "        [    0.22187,     0.22535,           2],\n",
      "        [    0.21563,     0.22535,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.19062,     0.23239,           2],\n",
      "        [    0.22031,     0.28638,           1],\n",
      "        [    0.18125,     0.29812,           1],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[        0.7,     0.23005,           2],\n",
      "        [    0.70781,     0.19718,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.76406,     0.17371,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.81719,     0.33568,           2],\n",
      "        [       0.75,     0.29577,           2],\n",
      "        [    0.80781,     0.54225,           2],\n",
      "        [     0.7125,     0.41784,           2],\n",
      "        [    0.69063,     0.58216,           2],\n",
      "        [    0.63906,     0.44836,           2],\n",
      "        [    0.78594,     0.69249,           2],\n",
      "        [     0.7375,     0.65258,           2],\n",
      "        [    0.75156,     0.92019,           2],\n",
      "        [    0.72031,     0.88028,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [   0.095312,     0.84507,           2],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [          0,           0,           0]],\n",
      "\n",
      "       [[    0.56406,     0.21596,           2],\n",
      "        [    0.57031,     0.20188,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.59062,     0.20188,           1],\n",
      "        [          0,           0,           0],\n",
      "        [    0.59844,     0.25117,           1],\n",
      "        [     0.5625,     0.24648,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.54844,     0.30516,           2],\n",
      "        [          0,           0,           0],\n",
      "        [    0.54531,     0.34507,           2],\n",
      "        [    0.59375,     0.36854,           2],\n",
      "        [    0.56406,     0.37089,           2],\n",
      "        [    0.59531,     0.47887,           1],\n",
      "        [    0.56719,     0.48357,           2],\n",
      "        [    0.59688,     0.56573,           1],\n",
      "        [    0.57187,     0.56338,           1]]], dtype=float32), 'normalized': True, 'bbox_format': 'xywh'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB True): 100%|██████████| 5/5 [00:00<00:00, 714.19it/s]\n",
      "Plotting labels to C:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 96 weight(decay=0.0), 140 weight(decay=0.0005), 121 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/1      4.11G     0.2737     0.9132     0.1237    0.04771     0.4296     0.1866          5        640:  33%|███▎      | 1/3 [00:01<00:02,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singulars : torch.Size([6]) torch.Size([6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      4.16G     0.2196     0.8955     0.1301    0.03759     0.4201     0.2182          2        640:  67%|██████▋   | 2/3 [00:01<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singulars : torch.Size([6]) torch.Size([6, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1      4.21G      0.416      0.597     0.2191    0.04926      0.587     0.1561          1        640: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix contains  Inf values\n",
      "Matrix is ill-conditioned with very large values\n",
      "Singulars : torch.Size([4]) torch.Size([6, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95):  50%|█████     | 1/2 [00:00<00:00,  4.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All singular values are zero. Skipping alignment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: All singular values are zero. Skipping alignment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   all          5         19     0.0081      0.632     0.0322    0.00819   0.000675     0.0526   0.000406   0.000365          0          0          0          0\n",
      "\n",
      "1 epochs completed in 0.002 hours.\n",
      "Optimizer stripped from C:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\\weights\\last.pt, 10.4MB\n",
      "Optimizer stripped from C:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\\weights\\best.pt, 10.4MB\n",
      "\n",
      "Validating C:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.207  Python-3.12.6 torch-2.5.1+cu118 CUDA:0 (NVIDIA GeForce RTX 4050 Laptop GPU, 6140MiB)\n",
      "mtYOLOv8_multitask_coco_ECA summary (fused): 370 layers, 4995750 parameters, 0 gradients, 12.6 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  8.61it/s]\n",
      "                   all          5         19     0.0081      0.632     0.0322    0.00819   0.000675     0.0526   0.000406   0.000365          0          0          0          0\n",
      "Speed: 0.8ms preprocess, 15.5ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\nikhi\\Desktop\\logs\\2025-01-13 23_mtyolov8_multitask_coco_ECA\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtyolov8_multitask_coco_ECA_ECA multitask training ends: 2025-01-13 23:09:56.034093 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_dataset:\n",
    "    for task in list_task:\n",
    "        for model_type in list_model_type:\n",
    "            for pretrained in list_pretrained:\n",
    "                if (task=='multitask') and (pretrained!=''):\n",
    "                    None\n",
    "                else:\n",
    "                    print(f'Dataset: {dataset}, Task: {task}, Model: {model_type}{pretrained}')\n",
    "\n",
    "                    ## Start training\n",
    "                    yolo_train(task=task, \n",
    "                               model_type=model_type, \n",
    "                               dir_mtYOLO_root=dir_mtYOLO_root, \n",
    "                               dataset=dataset,\n",
    "                               pretrained=pretrained,\n",
    "                               device=device,\n",
    "                               epochs=epochs, \n",
    "                               patience=patience,   \n",
    "                               image_size=image_size,\n",
    "                               batch_size=batch_size,\n",
    "                               model_name='mtyolov8'\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5588d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "\n",
    "class CBAM_Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class CBAM_ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(CBAM_ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            CBAM_Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                # lse_pool = cbam_logsumexp_2d(x)\n",
    "                x_flat = x.view(x.size(0), x.size(1), -1)\n",
    "                s, _ = torch.max(x_flat, dim=2, keepdim=True)\n",
    "                lse_pool = s + (x_flat - s).exp().sum(dim=2, keepdim=True).log()\n",
    "\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return x * scale\n",
    "\n",
    "\n",
    "class CBAM_ChannelPool(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "class CBAM_SpatialGate(nn.Module):\n",
    "    def __init__(self, bn=True):\n",
    "        super(CBAM_SpatialGate, self).__init__()\n",
    "        kernel_size = 7\n",
    "        self.compress = CBAM_ChannelPool()\n",
    "        self.spatial = Conv(2, 1, k=kernel_size, s=1, p=(kernel_size-1) // 2)\n",
    "    def forward(self, x):\n",
    "        x_compress = self.compress(x)\n",
    "        x_out = self.spatial(x_compress)\n",
    "        scale = F.sigmoid(x_out) \n",
    "        return x * scale\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def autopad(k, p=None, d=1):  # kernel, padding, dilation\n",
    "    \"\"\"Pad to 'same' shape outputs.\"\"\"\n",
    "    if d > 1:\n",
    "        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size\n",
    "    if p is None:\n",
    "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
    "    return p\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation).\"\"\"\n",
    "    default_act = nn.SiLU()  # default activation\n",
    "\n",
    "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n",
    "        \"\"\"Initialize Conv layer with given arguments including activation.\"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "    def forward_fuse(self, x):\n",
    "        \"\"\"Perform transposed convolution of 2D data.\"\"\"\n",
    "        return self.act(self.conv(x))\n",
    "    \n",
    "class BottleneckLinear(nn.Module):\n",
    "    def __init__(self, c2, expanded_dim, bottleneck_ratio=0.125):\n",
    "        super().__init__()\n",
    "        bottleneck_dim = int(c2 * bottleneck_ratio)\n",
    "        self.bottleneck = nn.Linear(c2, bottleneck_dim, bias=False)\n",
    "        self.expand = nn.Linear(bottleneck_dim, expanded_dim, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.bottleneck(x)\n",
    "        return self.expand(x)\n",
    "\n",
    "class AdvancedGatedAttentionBlock(nn.Module):\n",
    "    def __init__(self, c1,c2,k=1, s=1, p=None, g=1, d=1, act=True, \n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        conv_ratio=1\n",
    "        expansion_ratio=1\n",
    "        # norm_layer=partial(nn.LayerNorm, eps=1e-6)\n",
    "        self.dwconv = Conv(c1, c2, k=k, s=s,p=p, d=d, g=c1)\n",
    "        # Normalization Layer\n",
    "        # self.norm = norm_layer([c2])\n",
    "        \n",
    "        # Multi-Scale Feature Extraction\n",
    "        expanded_dim = int(c2 * expansion_ratio)\n",
    "        conv_channels = int(c2 * conv_ratio)\n",
    "\n",
    "        self.fc1 = BottleneckLinear(c2, expanded_dim*2)  # For gating and multi-scale features\n",
    "\n",
    "        # Multi-scale Convolutions\n",
    "        self.conv_3x3 = nn.Conv2d(conv_channels, conv_channels, kernel_size=3,\n",
    "                                  padding=3 // 2, groups=conv_channels)\n",
    "        self.conv_5x5 = nn.Conv2d(conv_channels, conv_channels, kernel_size=5,\n",
    "                                  padding=5 // 2, groups=conv_channels)\n",
    "\n",
    "        # Additive Attention\n",
    "        self.att_weight_fc = BottleneckLinear(expanded_dim, 1)  # Softmax for additive attention\n",
    "\n",
    "        # Final Linear Projection\n",
    "        self.fc2 = BottleneckLinear(expanded_dim, c2)\n",
    "\n",
    "        # Drop Path (Stochastic Depth)\n",
    "        self.drop_path = DropPath(0.1)\n",
    "        self.SpatialGate = CBAM_SpatialGate()\n",
    "        self.ChannelGate = CBAM_ChannelGate(c2, 16, ['avg', 'max'])\n",
    "        \n",
    "        # Activation\n",
    "        self.act = nn.SiLU() if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: [B, C, H, W]\n",
    "        # Using the convolutional operation if and only the input given dimensions are not equal. If both are different then use the Conv or else Skip\n",
    "        x = self.dwconv(x)\n",
    "        # Permute to [B, H, W, C] for layer normalization\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # shortcut = x  # Save shortcut connection\n",
    "        # x = self.norm(x)\n",
    "\n",
    "        # Gating and Multi-Scale Features\n",
    "\n",
    "        # Split the input tensor into two halves dynamically\n",
    "        fc1_out = self.fc1(x)  # Shape: [B, H, W, C]\n",
    "        split_size = fc1_out.size(-1) // 2  # Dynamically calculate split size\n",
    "        g, features = torch.split(fc1_out, [split_size, fc1_out.size(-1) - split_size], dim=-1)\n",
    "        \n",
    "        # Process multi-scale features (Split into channels for depthwise convolution)\n",
    "        shortcut = features\n",
    "        features = features.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n",
    "        features_3x3 = self.conv_3x3(features)\n",
    "        features_5x5 = self.conv_5x5(features)\n",
    "\n",
    "        # Combine multi-scale features\n",
    "        combined_features = features+features_3x3 + features_5x5\n",
    "\n",
    "        combined_features = self.ChannelGate(combined_features)\n",
    "        combined_features = self.SpatialGate(combined_features)\n",
    "        # Permute back to [B, H, W, C]\n",
    "        combined_features = combined_features.permute(0, 2, 3, 1)\n",
    "\n",
    "        # Additive Attention\n",
    "        \n",
    "        result = self.att_weight_fc(features.permute(0,2,3,1))\n",
    "        attention_weights = torch.softmax(result, dim=-1)\n",
    "        gated_output = self.act(g) * attention_weights\n",
    "\n",
    "        # Combine features\n",
    "        x = self.fc2(gated_output + combined_features)\n",
    "\n",
    "        # Drop path and residual connection\n",
    "        x = self.drop_path(x) + shortcut\n",
    "        return x.permute(0, 3, 1, 2)\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.drop_prob == 0. or not self.training:\n",
    "            return x\n",
    "        keep_prob = 1 - self.drop_prob\n",
    "        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "        random_tensor.floor_()\n",
    "        return x.div(keep_prob) * random_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979a9880",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchinfo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchinfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[0;32m      2\u001b[0m summary(AdvancedGatedAttentionBlock(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchinfo'"
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(AdvancedGatedAttentionBlock(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1acb23f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdvancedGatedAttentionBlock(64,64)\n",
    "input = torch.randn(224,224,64)\n",
    "input = input.permute(2,1,0).unsqueeze(0)\n",
    "out = a(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd67f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedCNNBlock(nn.Module):\n",
    "    def __init__(self, c1, dim, k=7, expansion_ratio=8/3, conv_ratio=1.0,\n",
    "                 norm_layer=partial(nn.LayerNorm,eps=1e-6), \n",
    "                 act_layer=nn.GELU,\n",
    "                 drop_path=0.,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.norm = norm_layer([dim])\n",
    "        hidden = int(expansion_ratio * dim)\n",
    "        self.fc1 = nn.Linear(dim, hidden * 2)\n",
    "        self.act = act_layer()\n",
    "        conv_channels = int(conv_ratio * dim)\n",
    "        self.split_indices = (hidden, hidden - conv_channels, conv_channels)\n",
    "        self.dwconv = nn.Conv2d(c1,dim, kernel_size=k, groups=1, padding=k//2)\n",
    "        self.conv = nn.Conv2d(conv_channels, conv_channels, kernel_size=k, padding=k//2, groups=conv_channels)\n",
    "        self.fc2 = nn.Linear(hidden, dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0,2,3,1)\n",
    "        shortcut = x # [B, H, W, C]\n",
    "        x = self.norm(x)\n",
    "        g, i, c = torch.split(self.fc1(x), self.split_indices, dim=-1)\n",
    "        c = c.permute(0, 3, 1, 2) # [B, H, W, C] -> [B, C, H, W]\n",
    "        c = self.conv(c)\n",
    "        c = c.permute(0, 2, 3, 1) # [B, C, H, W] -> [B, H, W, C]\n",
    "        x = self.fc2(self.act(g) * torch.cat((i, c), dim=-1))\n",
    "        x = self.drop_path(x)\n",
    "        out= x + shortcut\n",
    "        return out.permute(0,3,1,2)\n",
    "    \n",
    "a = GatedCNNBlock(64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e40de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = AdvancedGatedAttentionBlock(64,64)\n",
    "input = torch.randn(224,224,64)\n",
    "input = input.permute(2,1,0).unsqueeze(0)\n",
    "out = a(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb5e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_loss_weights(val_losses, hyp_list):\n",
    "    total_inverse_loss = sum(1/(loss+1e-6) for loss in val_losses)\n",
    "    dynamic_loss_weights = {task: hyp1*(1 / (loss + 1e-6)) / total_inverse_loss for task, loss, hyp1 in zip(loss_map, val_losses, hyp_list)}\n",
    "    return dynamic_loss_weights\n",
    "hyp = [7.5, 12.0, 1.0, 7.5, 0.5, 1.5]\n",
    "loss_map = ['box', 'pose', 'kobj', 'seg', 'cls', 'dfl']\n",
    "loss_values = [0.6034, 0.9177, 1.7240, 1.2664, 8.1688, 2.9225]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6238ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:/Users/nikhi/Desktop/ProjectX/params.csv\")\n",
    "params = df['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf55626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ea197",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_grads = torch.autograd.grad(task_loss, torch.Tensor(params, reqruires_grad=True), retain_graph=True, allow_unused=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5636f29",
   "metadata": {},
   "source": [
    "### Experimentation with Conv Blocks\n",
    "**Experiment Setup** : 2 epochs, 5 train images, 5 val images, ECA model, multitask (det, pose, seg), RTX 4050 6GB GPU\n",
    "\n",
    "#### Base Conv:\n",
    "- Params :5051264\n",
    "- GFLOPs :13.2\n",
    "- Test mAP50 = {\n",
    "    box : 0.0237,\n",
    "    pose : 0,\n",
    "    mask: 0}\n",
    "- Speed: 1.4ms preprocess, 20.0ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
    "\n",
    "#### CBAM Conv:\n",
    "- Params : 5354045\n",
    "- GLOPs: 25.8\n",
    "- Test mAP50 = {\n",
    "    box : 0.0315,\n",
    "    pose : 0.000372,\n",
    "    mask: 0.00145}\n",
    "- Time to Complete : 0.005 hrs\n",
    "- Speed: 0.4ms preprocess, 73.1ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
    "\n",
    "\n",
    "#### ConvNeXt Conv\n",
    "- Params : 11963050\n",
    "- GLOPs : 30.4\n",
    "- Test mAP50 = {\n",
    "    box : 0.0233,\n",
    "    pose : 0,\n",
    "    mask: 0.00181}\n",
    "- Time to complete : 0.005 hrs\n",
    "- Speed: 0.8ms preprocess, 56.9ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
    "\n",
    "\n",
    "#### InceptionNeXt Conv\n",
    "- Params : 11942464\n",
    "- GLOPs : 31.5\n",
    "- Test mAP50 = {\n",
    "    box : 0.0337,\n",
    "    pose : 0.00159,\n",
    "    mask: 0.00181}\n",
    "- Time to complete : 0.003 hrs\n",
    "- Speed: 1.8ms preprocess, 76.9ms inference, 0.0ms loss, 3.1ms postprocess per image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50624f70-14b1-4798-b5b1-76022b492226",
   "metadata": {},
   "source": [
    "# Validation / Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41f716-3c6f-43c8-8165-fd4a38cba055",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Validation and Prediction\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.models.yolo.multi import MultiTaskPredictor, MultiTaskValidator\n",
    "import datetime, os, glob\n",
    "\n",
    "model_mode = 'predict' #['val', 'predict']\n",
    "list_task = ['multitask']\n",
    "list_model_type = ['_ECA'] \n",
    "list_pretrained = [''] # Load existing pre-trained YOLO models (Only for pose and segmentation)\n",
    "list_dataset = ['coco']\n",
    "dir_log_root = 'C:/Users/nikhi/Desktop/mtYOLO/log_val' \n",
    "dir_image = \"C:/Users/nikhi/Desktop/val\"\n",
    "\n",
    "device = [0]\n",
    "image_size = 640\n",
    "batch_size = 256\n",
    "\n",
    "\n",
    "for dataset in list_dataset[:1]:\n",
    "    for task in list_task[:1]:\n",
    "        for model_type in list_model_type[:1]:\n",
    "            for pretrained in list_pretrained[:1]:\n",
    "                dir_model_checkpoint = max([file for file in sorted(glob.iglob(f'C:/Users/nikhi/Desktop/mtYOLO/model_checkpoint/mtyolov8_coco_multitask_ECA.pt', recursive=True))])\n",
    "                print(f'Task: {task}, Model: YOLOv8{model_type}{pretrained}, Directory of latest checkpoint: {dir_model_checkpoint}')\n",
    "                print(f\"{dir_image} exists: {os.path.exists(dir_image)}\")\n",
    "\n",
    "                ## Configuration\n",
    "                args = dict(\n",
    "                    model=dir_model_checkpoint, #Specifies the model file for training. Accepts a path to either a .pt pretrained model or a .yaml configuration file. Essential for defining the model structure or initializing weights.\n",
    "                    )\n",
    "\n",
    "                ## Load model\n",
    "                model = YOLO(**args)\n",
    "                \n",
    "                ## Print model information\n",
    "                model.info()\n",
    "\n",
    "                if model_mode=='val':\n",
    "                    ## Validation\n",
    "                    model.val(\n",
    "                        data = dir_image, #None, # Specifies the path to the dataset configuration file (e.g., coco8.yaml). This file includes paths to validation data, class names, and number of classes.\n",
    "                        imgsz = image_size, #640, # Defines the size of input images. All images are resized to this dimension before processing.\n",
    "                        # batch = 16, # Sets the number of images per batch. Use -1 for AutoBatch, which automatically adjusts based on GPU memory availability.\n",
    "                        # save_json = False, # If True, saves the results to a JSON file for further analysis or integration with other tools.\n",
    "                        # save_hybrid = True, #False, # If True, saves a hybrid version of labels that combines original annotations with additional model predictions.\n",
    "                        # conf = 0.001, # Sets the minimum confidence threshold for detections. Detections with confidence below this threshold are discarded.\n",
    "                        # iou = 0.6, # Sets the Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Helps in reducing duplicate detections.\n",
    "                        # max_det = 300, # Limits the maximum number of detections per image. Useful in dense scenes to prevent excessive detections.\n",
    "                        # half = True, # Enables half-precision (FP16) computation, reducing memory usage and potentially increasing speed with minimal impact on accuracy.\n",
    "                        device = device, #None, # Specifies the device for validation (cpu, cuda:0, etc.). Allows flexibility in utilizing CPU or GPU resources.\n",
    "                        # dnn = False, # If True, uses the OpenCV DNN module for ONNX model inference, offering an alternative to PyTorch inference methods.\n",
    "                        plots = True, # False, # When set to True, generates and saves plots of predictions versus ground truth for visual evaluation of the model's performance.\n",
    "                        # rect = False, # If True, uses rectangular inference for batching, reducing padding and potentially increasing speed and efficiency.\n",
    "                        # split = 'val' # Determines the dataset split to use for validation (val, test, or train). Allows flexibility in choosing the data segment for performance evaluation.\n",
    "                    )\n",
    "\n",
    "                if model_mode=='predict':\n",
    "                    ## Predict\n",
    "                    model.predict(\n",
    "                        source = dir_image, #\tSpecifies the data source for inference. Can be an image path, video file, directory, URL, or device ID for live feeds. Supports a wide range of formats and sources, enabling flexible application across different types of input.\n",
    "                        # conf = 0.25, # Sets the minimum confidence threshold for detections. Objects detected with confidence below this threshold will be disregarded. Adjusting this value can help reduce false positives.\n",
    "                        # iou = 0.7, # Intersection Over Union (IoU) threshold for Non-Maximum Suppression (NMS). Lower values result in fewer detections by eliminating overlapping boxes, useful for reducing duplicates.\n",
    "                        # imgsz = 640, # Defines the image size for inference. Can be a single integer 640 for square resizing or a (height, width) tuple. Proper sizing can improve detection accuracy and processing speed.\n",
    "                        # half = False, # Enables half-precision (FP16) inference, which can speed up model inference on supported GPUs with minimal impact on accuracy.\n",
    "                        # device = None, # Specifies the device for inference (e.g., cpu, cuda:0 or 0). Allows users to select between CPU, a specific GPU, or other compute devices for model execution.\n",
    "                        # max_det = 300, # Maximum number of detections allowed per image. Limits the total number of objects the model can detect in a single inference, preventing excessive outputs in dense scenes.\n",
    "                        # vid_stride = 1, # Frame stride for video inputs. Allows skipping frames in videos to speed up processing at the cost of temporal resolution. A value of 1 processes every frame, higher values skip frames.\n",
    "                        # stream_buffer = False, # Determines if all frames should be buffered when processing video streams (True), or if the model should return the most recent frame (False). Useful for real-time applications.\n",
    "                        # visualize = True, #False, # Activates visualization of model features during inference, providing insights into what the model is \"seeing\". Useful for debugging and model interpretation.\n",
    "                        # augment = False, # Enables test-time augmentation (TTA) for predictions, potentially improving detection robustness at the cost of inference speed.\n",
    "                        # agnostic_nms = False, # Enables class-agnostic Non-Maximum Suppression (NMS), which merges overlapping boxes of different classes. Useful in multi-class detection scenarios where class overlap is common.\n",
    "                        # classes = None, # Filters predictions to a set of class IDs. Only detections belonging to the specified classes will be returned. Useful for focusing on relevant objects in multi-class detection tasks.\n",
    "                        # retina_masks = False, # Uses high-resolution segmentation masks if available in the model. This can enhance mask quality for segmentation tasks, providing finer detail.\n",
    "                        # embed = None, # Specifies the layers from which to extract feature vectors or embeddings. Useful for downstream tasks like clustering or similarity search.\n",
    "                                        \n",
    "                        show = True, # If True, displays the annotated images or videos in a window. Useful for immediate visual feedback during development or testing.\n",
    "                        # save = False, # Enables saving of the annotated images or videos to file. Useful for documentation, further analysis, or sharing results.\n",
    "                        # save_frames = False, # When processing videos, saves individual frames as images. Useful for extracting specific frames or for detailed frame-by-frame analysis.\n",
    "                        # save_txt = False, # Saves detection results in a text file, following the format [class] [x_center] [y_center] [width] [height] [confidence]. Useful for integration with other analysis tools.\n",
    "                        # save_conf = False, # Includes confidence scores in the saved text files. Enhances the detail available for post-processing and analysis.\n",
    "                        # save_crop = False, # Saves cropped images of detections. Useful for dataset augmentation, analysis, or creating focused datasets for specific objects.\n",
    "                        # show_labels = True, # Displays labels for each detection in the visual output. Provides immediate understanding of detected objects.\n",
    "                        # show_conf = True, # Displays the confidence score for each detection alongside the label. Gives insight into the model's certainty for each detection.\n",
    "                        # show_boxes = True, # Draws bounding boxes around detected objects. Essential for visual identification and location of objects in images or video frames.\n",
    "                        # line_width = None\t# Specifies the line width of bounding boxes. If None, the line width is automatically adjusted based on the image size. Provides visual customization for clarity.\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce4dcf-8836-4559-ac07-2e1168ef0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multitask_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
